{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Multivariate Regression Analysis and Gradient Boosting with Lowess and XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "In this notebook I present Multivariate Regression Analysis and Gradient Boosting with Lowess, Random Forest Regression, a home-made boosted Lowess model, and  the Extreme Gradient Boosting method (XGB). I apply each method to an auto-MPG dataset, and a Boston Housing Prices dataset. I present conceptualizations of gradient boosting, and use KFold cross-validation to test each model. I found that for the MPG data, Extreme Gradient Boosting was the best option by a significant margin, and for Bston Housing data I found that the homemade gradient boosting method performed the best by a smaller margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.interpolate import interp1d, LinearNDInterpolator, NearestNDInterpolator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "These data sets are both quite small, and I am using them as two dimensional. For the boston housing data, I have selected the 'cmedv', or the median sale price per zipcode, as our target and, since this is multivariate regression, I am using all 14 features. For the 'cars' dataset, I've selected the miles-per-gallon of each car as the target, and again are using all of the features. Below are examples of the data. Neither is a good candidate for a regular linear regression.\n",
    "\n",
    "I did very little preprocessing on this data. It came quite well curated, so the only thing I needed to do was scale the features, for which I used scikitlearn's StandardScalar, and do a train test split (75% train, 25% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town</th>\n",
       "      <th>tract</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>crime</th>\n",
       "      <th>residential</th>\n",
       "      <th>industrial</th>\n",
       "      <th>river</th>\n",
       "      <th>nox</th>\n",
       "      <th>rooms</th>\n",
       "      <th>older</th>\n",
       "      <th>distance</th>\n",
       "      <th>highway</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>cmedv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nahant</td>\n",
       "      <td>2011</td>\n",
       "      <td>-70.955002</td>\n",
       "      <td>42.255001</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>no</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.199997</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swampscott</td>\n",
       "      <td>2021</td>\n",
       "      <td>-70.949997</td>\n",
       "      <td>42.287498</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>no</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Swampscott</td>\n",
       "      <td>2022</td>\n",
       "      <td>-70.935997</td>\n",
       "      <td>42.283001</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>no</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.099998</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marblehead</td>\n",
       "      <td>2031</td>\n",
       "      <td>-70.928001</td>\n",
       "      <td>42.292999</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>no</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.799999</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marblehead</td>\n",
       "      <td>2032</td>\n",
       "      <td>-70.921997</td>\n",
       "      <td>42.298000</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>no</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.200001</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         town  tract  longitude   latitude    crime  residential  industrial  \\\n",
       "0      Nahant   2011 -70.955002  42.255001  0.00632         18.0        2.31   \n",
       "1  Swampscott   2021 -70.949997  42.287498  0.02731          0.0        7.07   \n",
       "2  Swampscott   2022 -70.935997  42.283001  0.02729          0.0        7.07   \n",
       "3  Marblehead   2031 -70.928001  42.292999  0.03237          0.0        2.18   \n",
       "4  Marblehead   2032 -70.921997  42.298000  0.06905          0.0        2.18   \n",
       "\n",
       "  river    nox  rooms      older  distance  highway  tax    ptratio  lstat  \\\n",
       "0    no  0.538  6.575  65.199997    4.0900        1  296  15.300000   4.98   \n",
       "1    no  0.469  6.421  78.900002    4.9671        2  242  17.799999   9.14   \n",
       "2    no  0.469  7.185  61.099998    4.9671        2  242  17.799999   4.03   \n",
       "3    no  0.458  6.998  45.799999    6.0622        3  222  18.700001   2.94   \n",
       "4    no  0.458  7.147  54.200001    6.0622        3  222  18.700001   5.33   \n",
       "\n",
       "       cmedv  \n",
       "0  24.000000  \n",
       "1  21.600000  \n",
       "2  34.700001  \n",
       "3  33.400002  \n",
       "4  36.200001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto MPG Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>CYL</th>\n",
       "      <th>ENG</th>\n",
       "      <th>WGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  CYL    ENG   WGT\n",
       "0  18.0    8  307.0  3504\n",
       "1  15.0    8  350.0  3693\n",
       "2  18.0    8  318.0  3436\n",
       "3  16.0    8  304.0  3433\n",
       "4  17.0    8  302.0  3449"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing and Displaying Data\n",
    "\n",
    "cars = pd.read_csv('Data/cars.csv')\n",
    "boston = pd.read_csv('Data/Boston_Housing_Prices.csv')\n",
    "\n",
    "Cars = np.concatenate([cars[['ENG','CYL','WGT']].values, cars['MPG'].values.reshape(-1,1)], axis=1)\n",
    "Boston = np.concatenate([boston[['tract', 'longitude', 'latitude', 'crime', 'residential', 'industrial', 'nox', 'rooms', 'older', \n",
    "                                'distance', 'highway', 'tax', 'ptratio', 'lstat']].values, boston['cmedv'].values.reshape(-1,1)], axis=1)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=3)\n",
    "\n",
    "print(\"Boston Housing Data:\")\n",
    "display(boston.head())\n",
    "print(\"Auto MPG Data:\")\n",
    "display(cars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Methods and Models\n",
    "\n",
    "### Gradient Boosting\n",
    "Put simply, to \"boost\" a known regression model is to train n other regression models to predict the original model's residual errors, then add these predicted residuals to the original models test output. This results in a reduced error in the test output.\n",
    "\n",
    "### Extreme Gradient Boosting (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tricubic Kernel, Lowess, and Boosted Lowess definitions\n",
    "\n",
    "def Tricubic(x):\n",
    "  if len(x.shape) == 1:\n",
    "    x = x.reshape(-1,1)\n",
    "  d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>1,0,70/81*(1-d**3)**3)\n",
    "\n",
    "def lw_reg(X, y, xnew, kern, tau, intercept):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    n = len(X) # the number of observations\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    if len(y.shape)==1: # here we make column vectors\n",
    "      y = y.reshape(-1,1)\n",
    "\n",
    "    if len(X.shape)==1:\n",
    "      X = X.reshape(-1,1)\n",
    "    \n",
    "    if intercept:\n",
    "      X1 = np.column_stack([np.ones((len(X),1)),X])\n",
    "    else:\n",
    "      X1 = X\n",
    "\n",
    "    w = np.array([kern((X - X[i])/(2*tau)) for i in range(n)]) # here we compute n vectors of weights\n",
    "\n",
    "    #Looping through all X-points\n",
    "    for i in range(n):          \n",
    "        W = np.diag(w[:,i])\n",
    "        b = np.transpose(X1).dot(W).dot(y)\n",
    "        A = np.transpose(X1).dot(W).dot(X1)\n",
    "        #A = A + 0.001*np.eye(X1.shape[1]) # if we want L2 regularization\n",
    "        #theta = linalg.solve(A, b) # A*theta = b\n",
    "        beta, res, rnk, s = lstsq(A, b)\n",
    "        yest[i] = np.dot(X1[i],beta)\n",
    "    if X.shape[1]==1:\n",
    "      f = interp1d(X.flatten(),yest,fill_value='extrapolate')\n",
    "    else:\n",
    "      f = LinearNDInterpolator(X, yest)\n",
    "    output = f(xnew) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
    "    if sum(np.isnan(output))>0:\n",
    "      g = NearestNDInterpolator(X,y.ravel()) \n",
    "      # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
    "      output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
    "    return output\n",
    "\n",
    "def boosted_lwr(X, y, xnew, kern, tau, intercept): \n",
    "  # we need decision trees\n",
    "  # for training the boosted method we use X and y\n",
    "  Fx = lw_reg(X,y,X,kern,tau,intercept) # we need this for training the Decision Tree\n",
    "  # Now train the Decision Tree on y_i - F(x_i)\n",
    "  new_y = y - Fx\n",
    "  #model = DecisionTreeRegressor(max_depth=2, random_state=123)\n",
    "  model = RandomForestRegressor(n_estimators=100,max_depth=2)\n",
    "  #model = model_xgb\n",
    "  model.fit(X,new_y)\n",
    "  output = model.predict(xnew) + lw_reg(X,y,xnew,kern,tau,intercept)\n",
    "  return output    \n",
    "\n",
    "def rep_boosted_lwr(X, y, xtest, kern, tau, booster, nboost, intercept):\n",
    "  yhat = lw_reg(X,y,X,kern,tau,intercept)\n",
    "  yhat_test = lw_reg(X,y,xtest,kern,tau,intercept)\n",
    "  lw_error = y - yhat\n",
    "  for i in range(nboost):\n",
    "    booster.fit(X,lw_error)\n",
    "    yhat += booster.predict(X)\n",
    "    yhat_test += booster.predict(xtest)\n",
    "    lw_error = y - yhat\n",
    "  return yhat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Cross-validated Mean Squared Error for LWR is : 18.74002057325897\n",
      "The Cross-validated Mean Squared Error for BLWR is : 16.671541246819412\n",
      "The Cross-validated Mean Squared Error for RF is : 17.13980908049434\n",
      "The Cross-validated Mean Squared Error for XGB is : 16.313673784632016\n"
     ]
    }
   ],
   "source": [
    "#Cars Cross-Validation\n",
    "\n",
    "mse_lwr = []\n",
    "mse_blwr = []\n",
    "mse_rf = []\n",
    "mse_xgb = []\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "for i in range(12345,12350):\n",
    "  #print('Random State: ' + str(i))\n",
    "  kf = KFold(n_splits=10,shuffle=True,random_state=i)\n",
    "  # this is the random state cross-validation loop to make sure our results are real, not just the state being good/bad for a particular model\n",
    "  j = 0\n",
    "  for idxtrain, idxtest in kf.split(Cars[:,:2]):\n",
    "    j += 1\n",
    "    #Split the train and test data\n",
    "    xtrain = Cars[:,:2][idxtrain]\n",
    "    ytrain = Cars[:,-1][idxtrain]\n",
    "    ytest = Cars[:,-1][idxtest]\n",
    "    xtest = Cars[:,:2][idxtest]\n",
    "    xtrain = scale.fit_transform(xtrain)\n",
    "    xtest = scale.transform(xtest)\n",
    "    #print('Split Number: ' + str(j))\n",
    "\n",
    "    #Train and predict for LWR and boosted LWR\n",
    "    yhat_lwr = lw_reg(xtrain,ytrain, xtest,Tricubic,tau=1.2,intercept=True)\n",
    "    \n",
    "    #Boosted LWR with repeated boosting\n",
    "    booster_rf = RandomForestRegressor(n_estimators=100,max_depth=2)\n",
    "    yhat_blwr = rep_boosted_lwr(xtrain,ytrain,xtest,Tricubic,1.2,booster_rf,2,True)\n",
    "\n",
    "    #Train and predict with random forest\n",
    "    model_rf = RandomForestRegressor(n_estimators=100,max_depth=3)\n",
    "    model_rf.fit(xtrain,ytrain)\n",
    "    yhat_rf = model_rf.predict(xtest)\n",
    "\n",
    "    #Train and predict for XGB\n",
    "    model_xgb.fit(xtrain,ytrain)\n",
    "    yhat_xgb = model_xgb.predict(xtest)\n",
    "\n",
    "    #Append each model's MSE\n",
    "    mse_lwr.append(mse(ytest,yhat_lwr))\n",
    "    mse_blwr.append(mse(ytest,yhat_blwr))\n",
    "    mse_rf.append(mse(ytest,yhat_rf))\n",
    "    mse_xgb.append(mse(ytest,yhat_xgb))\n",
    "\n",
    "print('\\n')\n",
    "print('The Cross-validated Mean Squared Error for LWR is : '+str(np.mean(mse_lwr)))\n",
    "print('The Cross-validated Mean Squared Error for BLWR is : '+str(np.mean(mse_blwr)))\n",
    "print('The Cross-validated Mean Squared Error for RF is : '+str(np.mean(mse_rf)))\n",
    "print('The Cross-validated Mean Squared Error for XGB is : '+str(np.mean(mse_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Cross-validated Mean Squared Error for LWR is : 0.3587898269590638\n",
      "The Cross-validated Mean Squared Error for BLWR is : 0.35878982695906286\n",
      "The Cross-validated Mean Squared Error for RF is : 0.6216629815656345\n",
      "The Cross-validated Mean Squared Error for XGB is : 0.5754137982172873\n"
     ]
    }
   ],
   "source": [
    "#Boston Cross-Validation\n",
    "\n",
    "mse_lwr = []\n",
    "mse_blwr = []\n",
    "mse_rf = []\n",
    "mse_xgb = []\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "for i in range(12345,12350):\n",
    "  #print('Random State: ' + str(i))\n",
    "  kf = KFold(n_splits=10,shuffle=True,random_state=i)\n",
    "  # this is the random state cross-validation loop to make sure our results are real, not just the state being good/bad for a particular model\n",
    "  j = 0\n",
    "  for idxtrain, idxtest in kf.split(Cars[:,:13]):\n",
    "    j += 1\n",
    "    #Split the train and test data\n",
    "    xtrain = Cars[:,:13][idxtrain]\n",
    "    ytrain = Cars[:,-1][idxtrain]\n",
    "    ytest = Cars[:,-1][idxtest]\n",
    "    xtest = Cars[:,:13][idxtest]\n",
    "    xtrain = scale.fit_transform(xtrain)\n",
    "    xtest = scale.transform(xtest)\n",
    "    #print('Split Number: ' + str(j))\n",
    "\n",
    "    #Train and predict for LWR and boosted LWR\n",
    "    yhat_lwr = lw_reg(xtrain,ytrain, xtest,Tricubic,tau=1.2,intercept=True)\n",
    "    \n",
    "    #Boosted LWR with repeated boosting\n",
    "    booster_rf = RandomForestRegressor(n_estimators=100,max_depth=2)\n",
    "    yhat_blwr = rep_boosted_lwr(xtrain,ytrain,xtest,Tricubic,1.2,booster_rf,2,True)\n",
    "\n",
    "    #Train and predict with random forest\n",
    "    model_rf = RandomForestRegressor(n_estimators=100,max_depth=3)\n",
    "    model_rf.fit(xtrain,ytrain)\n",
    "    yhat_rf = model_rf.predict(xtest)\n",
    "\n",
    "    #Train and predict for XGB\n",
    "    model_xgb.fit(xtrain,ytrain)\n",
    "    yhat_xgb = model_xgb.predict(xtest)\n",
    "\n",
    "    #Append each model's MSE\n",
    "    mse_lwr.append(mse(ytest,yhat_lwr))\n",
    "    mse_blwr.append(mse(ytest,yhat_blwr))\n",
    "    mse_rf.append(mse(ytest,yhat_rf))\n",
    "    mse_xgb.append(mse(ytest,yhat_xgb))\n",
    "\n",
    "print('\\n')\n",
    "print('The Cross-validated Mean Squared Error for LWR is : '+str(np.mean(mse_lwr)))\n",
    "print('The Cross-validated Mean Squared Error for BLWR is : '+str(np.mean(mse_blwr)))\n",
    "print('The Cross-validated Mean Squared Error for RF is : '+str(np.mean(mse_rf)))\n",
    "print('The Cross-validated Mean Squared Error for XGB is : '+str(np.mean(mse_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcb747d185c8f44e1168864a551a03e205fcb027ae54ce950ab2eeb0271873b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
