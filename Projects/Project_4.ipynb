{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.interpolate import interp1d, LinearNDInterpolator, NearestNDInterpolator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tricubic Kernel, Lowess, and general Boosting definitions\n",
    "\n",
    "def Tricubic(x):\n",
    "  if len(x.shape) == 1:\n",
    "    x = x.reshape(-1,1)\n",
    "  d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>1,0,70/81*(1-d**3)**3)\n",
    "\n",
    "def lw_reg(X, y, xnew, kern, tau, intercept):\n",
    "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
    "    n = len(X) # the number of observations\n",
    "    yest = np.zeros(n)\n",
    "\n",
    "    if len(y.shape)==1: # here we make column vectors\n",
    "      y = y.reshape(-1,1)\n",
    "    if len(X.shape)==1:\n",
    "      X = X.reshape(-1,1)\n",
    "    if intercept:\n",
    "      X1 = np.column_stack([np.ones((len(X),1)),X])\n",
    "    else:\n",
    "      X1 = X\n",
    "\n",
    "    w = np.array([kern((X - X[i])/(2*tau)) for i in range(n)]) # here we compute n vectors of weights\n",
    "\n",
    "    #Looping through all X-points, solving for the predictions as linear combinations of inputs and weights matrix\n",
    "    for i in range(n):          \n",
    "        W = np.diag(w[:,i])\n",
    "        b = np.transpose(X1).dot(W).dot(y)\n",
    "        A = np.transpose(X1).dot(W).dot(X1)\n",
    "        #A = A + 0.001*np.eye(X1.shape[1]) # if we want L2 regularization\n",
    "        #theta = linalg.solve(A, b) # A*theta = b\n",
    "        beta, res, rnk, s = lstsq(A, b)\n",
    "        yest[i] = np.dot(X1[i],beta)\n",
    "    if X.shape[1]==1:\n",
    "      f = interp1d(X.flatten(),yest,fill_value='extrapolate')\n",
    "    else:\n",
    "      f = LinearNDInterpolator(X, yest)\n",
    "    output = f(xnew) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
    "    if sum(np.isnan(output))>0:\n",
    "      g = NearestNDInterpolator(X,y.ravel()) \n",
    "      # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
    "      output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
    "    return output  \n",
    "\n",
    "def rep_boosted_lwr(X, y, xtest, kern, tau, booster, nboost, intercept):\n",
    "  yhat = lw_reg(X,y,X,kern,tau,intercept) #get loess predictions on training data\n",
    "  yhat_test = lw_reg(X,y,xtest,kern,tau,intercept) #get loess predictions on testing data\n",
    "  lw_error = y - yhat #find the loess training residuals; these are what the booster will train on\n",
    "  #Below, fit the booster on train data and residuals, then add its predictions to the train/test predictions, then get new residuals\n",
    "  for i in range(nboost): \n",
    "    booster.fit(X, lw_error)\n",
    "    yhat += booster.predict(X)\n",
    "    yhat_test += booster.predict(xtest)\n",
    "    lw_error = y - yhat\n",
    "  return yhat_test\n",
    "\n",
    "def n_boost(X, y, xtest, model, nboost, booster, kern = None, tau = None, tau_b = None, \n",
    "            intercept = None, n_estimators=None , max_depth=None, model_nn = None):\n",
    "  if booster == 'LWR':\n",
    "    if model == 'LWR':\n",
    "      yhat = lw_reg(X,y,X,kern,tau,intercept) #get loess predictions on training data\n",
    "      yhat_test = lw_reg(X,y,xtest,kern,tau,intercept) #get loess predictions on testing data\n",
    "      lw_error = y - yhat #find the loess training residuals; these are what the booster will train on\n",
    "      for i in range(nboost): \n",
    "        yhat += lw_reg(X,lw_error,X,kern,tau_b,intercept)\n",
    "        yhat_test += lw_reg(X,lw_error,xtest,kern,tau_b,intercept)\n",
    "        lw_error = y - yhat\n",
    "      return yhat_test\n",
    "\n",
    "    if model == 'RF' or model == 'RFR':\n",
    "      model_rf = RandomForestRegressor(n_estimators=n_estimators,max_depth=max_depth)\n",
    "      model_rf.fit(X,y)\n",
    "      yhat_rf = model_rf.predict(X)\n",
    "      yhat_test = model_rf.predict(xtest)\n",
    "      rf_error = y - yhat_rf\n",
    "      for i in range(nboost): \n",
    "        yhat_rf += lw_reg(X,rf_error,X,kern,tau_b,intercept)\n",
    "        yhat_test += lw_reg(X,rf_error,xtest,kern,tau_b,intercept)\n",
    "        rf_error = y - yhat_rf\n",
    "      return yhat_test\n",
    "\n",
    "    if model == 'NN':\n",
    "      model_nn.fit(X,y,validation_split=0.3, epochs=100, batch_size=20, verbose=0, callbacks=[es])\n",
    "      yhat_nn = model_nn.predict(X)\n",
    "      yhat_test = model_nn.predict(xtest)\n",
    "      nn_error = y - yhat_nn\n",
    "      for i in range(nboost): \n",
    "        yhat_nn += lw_reg(X,nn_error,X,kern,tau_b,intercept)\n",
    "        yhat_test += lw_reg(X,nn_error,xtest,kern,tau_b,intercept)\n",
    "        nn_error = y-yhat_nn\n",
    "      return yhat_test\n",
    "\n",
    "  else:\n",
    "    if model == 'LWR':\n",
    "      yhat = lw_reg(X,y,X,kern,tau,intercept) #get loess predictions on training data\n",
    "      yhat_test = lw_reg(X,y,xtest,kern,tau,intercept) #get loess predictions on testing data\n",
    "      lw_error = y - yhat #find the loess training residuals; these are what the booster will train on\n",
    "      for i in range(nboost): \n",
    "        booster.fit(X, lw_error)\n",
    "        yhat += booster.predict(X)\n",
    "        yhat_test += booster.predict(xtest)\n",
    "        lw_error = y - yhat\n",
    "      return yhat_test\n",
    "\n",
    "    if model == 'RF' or model == 'RFR':\n",
    "      model_rf = RandomForestRegressor(n_estimators=n_estimators,max_depth=max_depth)\n",
    "      model_rf.fit(X,y)\n",
    "      yhat_rf = model_rf.predict(X)\n",
    "      yhat_test = model_rf.predict(xtest)\n",
    "      rf_error = y - yhat_rf\n",
    "      for i in range(nboost): \n",
    "        booster.fit(X, rf_error)\n",
    "        yhat_rf += booster.predict(X)\n",
    "        yhat_test += booster.predict(xtest)\n",
    "        rf_error = y - yhat_rf\n",
    "      return yhat_test\n",
    "\n",
    "    if model == 'NN':\n",
    "      model_nn.fit(X,y,validation_split=0.3, epochs=100, batch_size=20, verbose=0, callbacks=[es])\n",
    "      yhat_nn = model_nn.predict(X)\n",
    "      yhat_test = model_nn.predict(xtest)\n",
    "      nn_error = y - yhat_nn\n",
    "      for i in range(nboost): \n",
    "        booster.fit(X, nn_error)\n",
    "        yhat_nn += booster.predict(X)\n",
    "        yhat_test += booster.predict(xtest)\n",
    "        nn_error = y - yhat_nn\n",
    "      return yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Neural Network and XGB Architectures\\nmodel_nn = Sequential() #Making a tensorflow sequential network\\nmodel_nn.add(Dense(128, activation=\"relu\", input_dim=6))\\nmodel_nn.add(Dropout(0.1))\\nmodel_nn.add(Dense(64, activation=\"relu\"))\\nmodel_nn.add(Dropout(0.1))\\nmodel_nn.add(Dense(1, activation=\"linear\"))\\nmodel_nn.compile(loss=\\'mean_squared_error\\', optimizer=Adam(learning_rate= 0.001, decay = 0.0001))\\nes = EarlyStopping(monitor=\\'val_loss\\', mode=\\'min\\', verbose=1, patience=600)\\n\\nbooster_nn = Sequential()\\nbooster_nn.add(Dense(32, activation=\"relu\", input_dim=6))\\nbooster_nn.add(Dropout(0.2))\\nbooster_nn.add(Dense(16, activation=\"relu\"))\\nbooster_nn.add(Dropout(0.2))\\nbooster_nn.add(Dense(1, activation=\"linear\"))\\nbooster_nn.compile(loss=\\'mean_squared_error\\', optimizer=Adam(learning_rate= 0.001, decay = 0.0001))\\nes = EarlyStopping(monitor=\\'val_loss\\', mode=\\'min\\', verbose=1, patience=600)\\n\\nmodel_xgb = xgb.XGBRegressor(objective =\\'reg:squarederror\\',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=3)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Neural Network and XGB Architectures\n",
    "model_nn = Sequential() #Making a tensorflow sequential network\n",
    "model_nn.add(Dense(128, activation=\"relu\", input_dim=6))\n",
    "model_nn.add(Dropout(0.1))\n",
    "model_nn.add(Dense(64, activation=\"relu\"))\n",
    "model_nn.add(Dropout(0.1))\n",
    "model_nn.add(Dense(1, activation=\"linear\"))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer=Adam(learning_rate= 0.001, decay = 0.0001))\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=600)\n",
    "\n",
    "booster_nn = Sequential()\n",
    "booster_nn.add(Dense(32, activation=\"relu\", input_dim=6))\n",
    "booster_nn.add(Dropout(0.2))\n",
    "booster_nn.add(Dense(16, activation=\"relu\"))\n",
    "booster_nn.add(Dropout(0.2))\n",
    "booster_nn.add(Dense(1, activation=\"linear\"))\n",
    "booster_nn.compile(loss='mean_squared_error', optimizer=Adam(learning_rate= 0.001, decay = 0.0001))\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=600)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=3)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/Concrete_Data.csv\")\n",
    "data = np.concatenate([data[data.columns[0:6]].values, data[data.columns[-1]].values.reshape(-1,1)], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelkshake\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 260.501\n",
      "[2]\tvalid_0's l2: 235.115\n",
      "[3]\tvalid_0's l2: 214.276\n",
      "[4]\tvalid_0's l2: 196.958\n",
      "[5]\tvalid_0's l2: 183.648\n",
      "[6]\tvalid_0's l2: 172.04\n",
      "[7]\tvalid_0's l2: 163.271\n",
      "[8]\tvalid_0's l2: 155.262\n",
      "[9]\tvalid_0's l2: 147.55\n",
      "[10]\tvalid_0's l2: 142.83\n",
      "[11]\tvalid_0's l2: 138.304\n",
      "[12]\tvalid_0's l2: 134.547\n",
      "[13]\tvalid_0's l2: 131.652\n",
      "[14]\tvalid_0's l2: 128.582\n",
      "[15]\tvalid_0's l2: 126.265\n",
      "[16]\tvalid_0's l2: 125.554\n",
      "[17]\tvalid_0's l2: 124.069\n",
      "[18]\tvalid_0's l2: 122.762\n",
      "[19]\tvalid_0's l2: 122.24\n",
      "[20]\tvalid_0's l2: 121.835\n",
      "[21]\tvalid_0's l2: 121.715\n",
      "[22]\tvalid_0's l2: 121.167\n",
      "[23]\tvalid_0's l2: 121.343\n",
      "[24]\tvalid_0's l2: 121.255\n",
      "[25]\tvalid_0's l2: 120.937\n",
      "[26]\tvalid_0's l2: 120.863\n",
      "[27]\tvalid_0's l2: 121.183\n",
      "[28]\tvalid_0's l2: 121.615\n",
      "[29]\tvalid_0's l2: 121.503\n",
      "[30]\tvalid_0's l2: 121.425\n",
      "[31]\tvalid_0's l2: 121.692\n",
      "[32]\tvalid_0's l2: 122.013\n",
      "[33]\tvalid_0's l2: 122.342\n",
      "[34]\tvalid_0's l2: 122.504\n",
      "[35]\tvalid_0's l2: 122.78\n",
      "[36]\tvalid_0's l2: 123.505\n",
      "[37]\tvalid_0's l2: 123.976\n",
      "[38]\tvalid_0's l2: 124.278\n",
      "[39]\tvalid_0's l2: 124.96\n",
      "[40]\tvalid_0's l2: 125.182\n",
      "[41]\tvalid_0's l2: 125.756\n",
      "[42]\tvalid_0's l2: 125.909\n",
      "[43]\tvalid_0's l2: 126.385\n",
      "[44]\tvalid_0's l2: 126.542\n",
      "[45]\tvalid_0's l2: 126.868\n",
      "[46]\tvalid_0's l2: 126.861\n",
      "[47]\tvalid_0's l2: 127.364\n",
      "[48]\tvalid_0's l2: 127.671\n",
      "[49]\tvalid_0's l2: 128.078\n",
      "[50]\tvalid_0's l2: 128.404\n",
      "[51]\tvalid_0's l2: 128.798\n",
      "[52]\tvalid_0's l2: 129.001\n",
      "[53]\tvalid_0's l2: 129.508\n",
      "[54]\tvalid_0's l2: 129.559\n",
      "[55]\tvalid_0's l2: 129.837\n",
      "[56]\tvalid_0's l2: 130.484\n",
      "[57]\tvalid_0's l2: 130.8\n",
      "[58]\tvalid_0's l2: 131.13\n",
      "[59]\tvalid_0's l2: 131.435\n",
      "[60]\tvalid_0's l2: 131.638\n",
      "[61]\tvalid_0's l2: 131.976\n",
      "[62]\tvalid_0's l2: 132.038\n",
      "[63]\tvalid_0's l2: 132.258\n",
      "[64]\tvalid_0's l2: 132.481\n",
      "[65]\tvalid_0's l2: 132.576\n",
      "[66]\tvalid_0's l2: 132.697\n",
      "[67]\tvalid_0's l2: 133.036\n",
      "[68]\tvalid_0's l2: 133.395\n",
      "[69]\tvalid_0's l2: 133.521\n",
      "[70]\tvalid_0's l2: 133.7\n",
      "[71]\tvalid_0's l2: 134.013\n",
      "[72]\tvalid_0's l2: 134.175\n",
      "[73]\tvalid_0's l2: 134.267\n",
      "[74]\tvalid_0's l2: 134.399\n",
      "[75]\tvalid_0's l2: 134.643\n",
      "[76]\tvalid_0's l2: 134.975\n",
      "[77]\tvalid_0's l2: 135.142\n",
      "[78]\tvalid_0's l2: 135.441\n",
      "[79]\tvalid_0's l2: 135.704\n",
      "[80]\tvalid_0's l2: 135.945\n",
      "[81]\tvalid_0's l2: 136.156\n",
      "[82]\tvalid_0's l2: 136.296\n",
      "[83]\tvalid_0's l2: 136.594\n",
      "[84]\tvalid_0's l2: 136.68\n",
      "[85]\tvalid_0's l2: 136.89\n",
      "[86]\tvalid_0's l2: 137.056\n",
      "[87]\tvalid_0's l2: 137.306\n",
      "[88]\tvalid_0's l2: 137.528\n",
      "[89]\tvalid_0's l2: 137.763\n",
      "[90]\tvalid_0's l2: 138.006\n",
      "[91]\tvalid_0's l2: 138.208\n",
      "[92]\tvalid_0's l2: 138.387\n",
      "[93]\tvalid_0's l2: 138.557\n",
      "[94]\tvalid_0's l2: 138.741\n",
      "[95]\tvalid_0's l2: 139.06\n",
      "[96]\tvalid_0's l2: 139.113\n",
      "[97]\tvalid_0's l2: 139.277\n",
      "[98]\tvalid_0's l2: 139.369\n",
      "[99]\tvalid_0's l2: 139.499\n",
      "[100]\tvalid_0's l2: 139.573\n",
      "[101]\tvalid_0's l2: 139.815\n",
      "[102]\tvalid_0's l2: 139.934\n",
      "[103]\tvalid_0's l2: 140.178\n",
      "[104]\tvalid_0's l2: 140.222\n",
      "[105]\tvalid_0's l2: 140.499\n",
      "[106]\tvalid_0's l2: 140.793\n",
      "[107]\tvalid_0's l2: 140.954\n",
      "[108]\tvalid_0's l2: 141.143\n",
      "[109]\tvalid_0's l2: 141.198\n",
      "[110]\tvalid_0's l2: 141.449\n",
      "[111]\tvalid_0's l2: 141.484\n",
      "[112]\tvalid_0's l2: 141.554\n",
      "[113]\tvalid_0's l2: 141.589\n",
      "[114]\tvalid_0's l2: 141.776\n",
      "[115]\tvalid_0's l2: 141.884\n",
      "[116]\tvalid_0's l2: 142.065\n",
      "[117]\tvalid_0's l2: 142.17\n",
      "[118]\tvalid_0's l2: 142.356\n",
      "[119]\tvalid_0's l2: 142.513\n",
      "[120]\tvalid_0's l2: 142.695\n",
      "[121]\tvalid_0's l2: 142.967\n",
      "[122]\tvalid_0's l2: 143.011\n",
      "[123]\tvalid_0's l2: 143.183\n",
      "[124]\tvalid_0's l2: 143.392\n",
      "[125]\tvalid_0's l2: 143.602\n",
      "[126]\tvalid_0's l2: 143.736\n",
      "[127]\tvalid_0's l2: 144.063\n",
      "[128]\tvalid_0's l2: 144.351\n",
      "[129]\tvalid_0's l2: 144.553\n",
      "[130]\tvalid_0's l2: 144.692\n",
      "[131]\tvalid_0's l2: 144.73\n",
      "[132]\tvalid_0's l2: 144.862\n",
      "[133]\tvalid_0's l2: 144.967\n",
      "[134]\tvalid_0's l2: 145.168\n",
      "[135]\tvalid_0's l2: 145.342\n",
      "[136]\tvalid_0's l2: 145.583\n",
      "[137]\tvalid_0's l2: 145.65\n",
      "[138]\tvalid_0's l2: 145.843\n",
      "[139]\tvalid_0's l2: 146.033\n",
      "[140]\tvalid_0's l2: 146.167\n",
      "[141]\tvalid_0's l2: 146.344\n",
      "[142]\tvalid_0's l2: 146.431\n",
      "[143]\tvalid_0's l2: 146.579\n",
      "[144]\tvalid_0's l2: 146.744\n",
      "[145]\tvalid_0's l2: 146.871\n",
      "[146]\tvalid_0's l2: 146.979\n",
      "[147]\tvalid_0's l2: 147.111\n",
      "[148]\tvalid_0's l2: 147.17\n",
      "[149]\tvalid_0's l2: 147.278\n",
      "[150]\tvalid_0's l2: 147.501\n",
      "[151]\tvalid_0's l2: 147.71\n",
      "[152]\tvalid_0's l2: 147.781\n",
      "[153]\tvalid_0's l2: 147.875\n",
      "[154]\tvalid_0's l2: 147.948\n",
      "[155]\tvalid_0's l2: 148.054\n",
      "[156]\tvalid_0's l2: 148.143\n",
      "[157]\tvalid_0's l2: 148.316\n",
      "[158]\tvalid_0's l2: 148.418\n",
      "[159]\tvalid_0's l2: 148.464\n",
      "[160]\tvalid_0's l2: 148.527\n",
      "[161]\tvalid_0's l2: 148.538\n",
      "[162]\tvalid_0's l2: 148.654\n",
      "[163]\tvalid_0's l2: 148.734\n",
      "[164]\tvalid_0's l2: 148.813\n",
      "[165]\tvalid_0's l2: 148.968\n",
      "[166]\tvalid_0's l2: 149.18\n",
      "[167]\tvalid_0's l2: 149.225\n",
      "[168]\tvalid_0's l2: 149.366\n",
      "[169]\tvalid_0's l2: 149.526\n",
      "[170]\tvalid_0's l2: 149.622\n",
      "[171]\tvalid_0's l2: 149.7\n",
      "[172]\tvalid_0's l2: 149.803\n",
      "[173]\tvalid_0's l2: 149.921\n",
      "[174]\tvalid_0's l2: 149.975\n",
      "[175]\tvalid_0's l2: 150.079\n",
      "[176]\tvalid_0's l2: 150.199\n",
      "[177]\tvalid_0's l2: 150.315\n",
      "[178]\tvalid_0's l2: 150.368\n",
      "[179]\tvalid_0's l2: 150.464\n",
      "[180]\tvalid_0's l2: 150.561\n",
      "[181]\tvalid_0's l2: 150.698\n",
      "[182]\tvalid_0's l2: 150.779\n",
      "[183]\tvalid_0's l2: 150.916\n",
      "[184]\tvalid_0's l2: 151.039\n",
      "[185]\tvalid_0's l2: 151.007\n",
      "[186]\tvalid_0's l2: 151.159\n",
      "[187]\tvalid_0's l2: 151.27\n",
      "[188]\tvalid_0's l2: 151.423\n",
      "[189]\tvalid_0's l2: 151.537\n",
      "[190]\tvalid_0's l2: 151.654\n",
      "[191]\tvalid_0's l2: 151.728\n",
      "[192]\tvalid_0's l2: 151.842\n",
      "[193]\tvalid_0's l2: 151.895\n",
      "[194]\tvalid_0's l2: 151.903\n",
      "[195]\tvalid_0's l2: 152.003\n",
      "[196]\tvalid_0's l2: 152.084\n",
      "[197]\tvalid_0's l2: 152.181\n",
      "[198]\tvalid_0's l2: 152.291\n",
      "[199]\tvalid_0's l2: 152.419\n",
      "[200]\tvalid_0's l2: 152.487\n",
      "5.19Minutes in Split Number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelkshake\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 293\n",
      "[2]\tvalid_0's l2: 274.83\n",
      "[3]\tvalid_0's l2: 257.588\n",
      "[4]\tvalid_0's l2: 245.071\n",
      "[5]\tvalid_0's l2: 233.479\n",
      "[6]\tvalid_0's l2: 224.411\n",
      "[7]\tvalid_0's l2: 217.92\n",
      "[8]\tvalid_0's l2: 213.015\n",
      "[9]\tvalid_0's l2: 207.388\n",
      "[10]\tvalid_0's l2: 204.352\n",
      "[11]\tvalid_0's l2: 200.732\n",
      "[12]\tvalid_0's l2: 196.996\n",
      "[13]\tvalid_0's l2: 195.289\n",
      "[14]\tvalid_0's l2: 192.787\n",
      "[15]\tvalid_0's l2: 191.067\n",
      "[16]\tvalid_0's l2: 189.507\n",
      "[17]\tvalid_0's l2: 188.235\n",
      "[18]\tvalid_0's l2: 186.577\n",
      "[19]\tvalid_0's l2: 185.72\n",
      "[20]\tvalid_0's l2: 184.947\n",
      "[21]\tvalid_0's l2: 183.549\n",
      "[22]\tvalid_0's l2: 182.715\n",
      "[23]\tvalid_0's l2: 182.465\n",
      "[24]\tvalid_0's l2: 181.496\n",
      "[25]\tvalid_0's l2: 180.4\n",
      "[26]\tvalid_0's l2: 179.467\n",
      "[27]\tvalid_0's l2: 178.463\n",
      "[28]\tvalid_0's l2: 178.229\n",
      "[29]\tvalid_0's l2: 177.701\n",
      "[30]\tvalid_0's l2: 177.13\n",
      "[31]\tvalid_0's l2: 176.436\n",
      "[32]\tvalid_0's l2: 175.62\n",
      "[33]\tvalid_0's l2: 175.13\n",
      "[34]\tvalid_0's l2: 175.056\n",
      "[35]\tvalid_0's l2: 174.9\n",
      "[36]\tvalid_0's l2: 174.895\n",
      "[37]\tvalid_0's l2: 174.9\n",
      "[38]\tvalid_0's l2: 174.742\n",
      "[39]\tvalid_0's l2: 174.397\n",
      "[40]\tvalid_0's l2: 173.945\n",
      "[41]\tvalid_0's l2: 173.616\n",
      "[42]\tvalid_0's l2: 173.169\n",
      "[43]\tvalid_0's l2: 173.028\n",
      "[44]\tvalid_0's l2: 172.77\n",
      "[45]\tvalid_0's l2: 172.813\n",
      "[46]\tvalid_0's l2: 172.681\n",
      "[47]\tvalid_0's l2: 172.876\n",
      "[48]\tvalid_0's l2: 172.752\n",
      "[49]\tvalid_0's l2: 172.982\n",
      "[50]\tvalid_0's l2: 172.653\n",
      "[51]\tvalid_0's l2: 172.794\n",
      "[52]\tvalid_0's l2: 172.626\n",
      "[53]\tvalid_0's l2: 172.863\n",
      "[54]\tvalid_0's l2: 172.483\n",
      "[55]\tvalid_0's l2: 172.722\n",
      "[56]\tvalid_0's l2: 172.835\n",
      "[57]\tvalid_0's l2: 173.221\n",
      "[58]\tvalid_0's l2: 173.365\n",
      "[59]\tvalid_0's l2: 173.287\n",
      "[60]\tvalid_0's l2: 173.05\n",
      "[61]\tvalid_0's l2: 173.171\n",
      "[62]\tvalid_0's l2: 172.959\n",
      "[63]\tvalid_0's l2: 172.947\n",
      "[64]\tvalid_0's l2: 172.949\n",
      "[65]\tvalid_0's l2: 172.828\n",
      "[66]\tvalid_0's l2: 173.034\n",
      "[67]\tvalid_0's l2: 172.97\n",
      "[68]\tvalid_0's l2: 173.119\n",
      "[69]\tvalid_0's l2: 173.2\n",
      "[70]\tvalid_0's l2: 173.109\n",
      "[71]\tvalid_0's l2: 173.156\n",
      "[72]\tvalid_0's l2: 173.389\n",
      "[73]\tvalid_0's l2: 173.466\n",
      "[74]\tvalid_0's l2: 173.444\n",
      "[75]\tvalid_0's l2: 173.567\n",
      "[76]\tvalid_0's l2: 173.396\n",
      "[77]\tvalid_0's l2: 173.378\n",
      "[78]\tvalid_0's l2: 173.57\n",
      "[79]\tvalid_0's l2: 173.555\n",
      "[80]\tvalid_0's l2: 173.813\n",
      "[81]\tvalid_0's l2: 173.909\n",
      "[82]\tvalid_0's l2: 173.944\n",
      "[83]\tvalid_0's l2: 173.964\n",
      "[84]\tvalid_0's l2: 174.109\n",
      "[85]\tvalid_0's l2: 174.356\n",
      "[86]\tvalid_0's l2: 174.41\n",
      "[87]\tvalid_0's l2: 174.344\n",
      "[88]\tvalid_0's l2: 174.588\n",
      "[89]\tvalid_0's l2: 174.823\n",
      "[90]\tvalid_0's l2: 174.91\n",
      "[91]\tvalid_0's l2: 175.024\n",
      "[92]\tvalid_0's l2: 175.141\n",
      "[93]\tvalid_0's l2: 175.41\n",
      "[94]\tvalid_0's l2: 175.511\n",
      "[95]\tvalid_0's l2: 175.51\n",
      "[96]\tvalid_0's l2: 175.674\n",
      "[97]\tvalid_0's l2: 175.773\n",
      "[98]\tvalid_0's l2: 175.855\n",
      "[99]\tvalid_0's l2: 175.897\n",
      "[100]\tvalid_0's l2: 175.99\n",
      "[101]\tvalid_0's l2: 176.198\n",
      "[102]\tvalid_0's l2: 176.269\n",
      "[103]\tvalid_0's l2: 176.274\n",
      "[104]\tvalid_0's l2: 176.206\n",
      "[105]\tvalid_0's l2: 176.249\n",
      "[106]\tvalid_0's l2: 176.477\n",
      "[107]\tvalid_0's l2: 176.674\n",
      "[108]\tvalid_0's l2: 176.816\n",
      "[109]\tvalid_0's l2: 176.932\n",
      "[110]\tvalid_0's l2: 176.97\n",
      "[111]\tvalid_0's l2: 177.2\n",
      "[112]\tvalid_0's l2: 177.242\n",
      "[113]\tvalid_0's l2: 177.266\n",
      "[114]\tvalid_0's l2: 177.321\n",
      "[115]\tvalid_0's l2: 177.257\n",
      "[116]\tvalid_0's l2: 177.439\n",
      "[117]\tvalid_0's l2: 177.444\n",
      "[118]\tvalid_0's l2: 177.671\n",
      "[119]\tvalid_0's l2: 177.683\n",
      "[120]\tvalid_0's l2: 177.699\n",
      "[121]\tvalid_0's l2: 177.662\n",
      "[122]\tvalid_0's l2: 177.68\n",
      "[123]\tvalid_0's l2: 177.832\n",
      "[124]\tvalid_0's l2: 178.059\n",
      "[125]\tvalid_0's l2: 178.014\n",
      "[126]\tvalid_0's l2: 178.14\n",
      "[127]\tvalid_0's l2: 177.951\n",
      "[128]\tvalid_0's l2: 178.139\n",
      "[129]\tvalid_0's l2: 178.206\n",
      "[130]\tvalid_0's l2: 178.292\n",
      "[131]\tvalid_0's l2: 178.313\n",
      "[132]\tvalid_0's l2: 178.447\n",
      "[133]\tvalid_0's l2: 178.55\n",
      "[134]\tvalid_0's l2: 178.608\n",
      "[135]\tvalid_0's l2: 178.43\n",
      "[136]\tvalid_0's l2: 178.444\n",
      "[137]\tvalid_0's l2: 178.482\n",
      "[138]\tvalid_0's l2: 178.497\n",
      "[139]\tvalid_0's l2: 178.568\n",
      "[140]\tvalid_0's l2: 178.586\n",
      "[141]\tvalid_0's l2: 178.659\n",
      "[142]\tvalid_0's l2: 178.57\n",
      "[143]\tvalid_0's l2: 178.602\n",
      "[144]\tvalid_0's l2: 178.675\n",
      "[145]\tvalid_0's l2: 178.734\n",
      "[146]\tvalid_0's l2: 178.776\n",
      "[147]\tvalid_0's l2: 178.788\n",
      "[148]\tvalid_0's l2: 178.769\n",
      "[149]\tvalid_0's l2: 178.806\n",
      "[150]\tvalid_0's l2: 178.803\n",
      "[151]\tvalid_0's l2: 178.866\n",
      "[152]\tvalid_0's l2: 178.957\n",
      "[153]\tvalid_0's l2: 178.987\n",
      "[154]\tvalid_0's l2: 178.982\n",
      "[155]\tvalid_0's l2: 179.019\n",
      "[156]\tvalid_0's l2: 178.943\n",
      "[157]\tvalid_0's l2: 179.002\n",
      "[158]\tvalid_0's l2: 179.093\n",
      "[159]\tvalid_0's l2: 179.17\n",
      "[160]\tvalid_0's l2: 179.308\n",
      "[161]\tvalid_0's l2: 179.442\n",
      "[162]\tvalid_0's l2: 179.54\n",
      "[163]\tvalid_0's l2: 179.605\n",
      "[164]\tvalid_0's l2: 179.654\n",
      "[165]\tvalid_0's l2: 179.744\n",
      "[166]\tvalid_0's l2: 179.844\n",
      "[167]\tvalid_0's l2: 179.897\n",
      "[168]\tvalid_0's l2: 179.912\n",
      "[169]\tvalid_0's l2: 179.898\n",
      "[170]\tvalid_0's l2: 180.023\n",
      "[171]\tvalid_0's l2: 180.008\n",
      "[172]\tvalid_0's l2: 180.076\n",
      "[173]\tvalid_0's l2: 180.063\n",
      "[174]\tvalid_0's l2: 180.05\n",
      "[175]\tvalid_0's l2: 180.146\n",
      "[176]\tvalid_0's l2: 180.15\n",
      "[177]\tvalid_0's l2: 180.134\n",
      "[178]\tvalid_0's l2: 180.065\n",
      "[179]\tvalid_0's l2: 180.125\n",
      "[180]\tvalid_0's l2: 180.265\n",
      "[181]\tvalid_0's l2: 180.298\n",
      "[182]\tvalid_0's l2: 180.338\n",
      "[183]\tvalid_0's l2: 180.318\n",
      "[184]\tvalid_0's l2: 180.277\n",
      "[185]\tvalid_0's l2: 180.339\n",
      "[186]\tvalid_0's l2: 180.408\n",
      "[187]\tvalid_0's l2: 180.446\n",
      "[188]\tvalid_0's l2: 180.53\n",
      "[189]\tvalid_0's l2: 180.543\n",
      "[190]\tvalid_0's l2: 180.586\n",
      "[191]\tvalid_0's l2: 180.65\n",
      "[192]\tvalid_0's l2: 180.667\n",
      "[193]\tvalid_0's l2: 180.75\n",
      "[194]\tvalid_0's l2: 180.859\n",
      "[195]\tvalid_0's l2: 180.89\n",
      "[196]\tvalid_0's l2: 180.898\n",
      "[197]\tvalid_0's l2: 180.96\n",
      "[198]\tvalid_0's l2: 181.01\n",
      "[199]\tvalid_0's l2: 181.003\n",
      "[200]\tvalid_0's l2: 181.081\n",
      "5.6Minutes in Split Number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelkshake\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 241.32\n",
      "[2]\tvalid_0's l2: 224.485\n",
      "[3]\tvalid_0's l2: 210.27\n",
      "[4]\tvalid_0's l2: 198.138\n",
      "[5]\tvalid_0's l2: 189.176\n",
      "[6]\tvalid_0's l2: 179.696\n",
      "[7]\tvalid_0's l2: 173.909\n",
      "[8]\tvalid_0's l2: 168.421\n",
      "[9]\tvalid_0's l2: 164.048\n",
      "[10]\tvalid_0's l2: 160.437\n",
      "[11]\tvalid_0's l2: 157.673\n",
      "[12]\tvalid_0's l2: 155.48\n",
      "[13]\tvalid_0's l2: 154.292\n",
      "[14]\tvalid_0's l2: 153.553\n",
      "[15]\tvalid_0's l2: 152.884\n",
      "[16]\tvalid_0's l2: 152.379\n",
      "[17]\tvalid_0's l2: 151.91\n",
      "[18]\tvalid_0's l2: 151.504\n",
      "[19]\tvalid_0's l2: 151.223\n",
      "[20]\tvalid_0's l2: 151.294\n",
      "[21]\tvalid_0's l2: 151.281\n",
      "[22]\tvalid_0's l2: 151.477\n",
      "[23]\tvalid_0's l2: 151.82\n",
      "[24]\tvalid_0's l2: 151.611\n",
      "[25]\tvalid_0's l2: 152.663\n",
      "[26]\tvalid_0's l2: 152.801\n",
      "[27]\tvalid_0's l2: 153.604\n",
      "[28]\tvalid_0's l2: 154.905\n",
      "[29]\tvalid_0's l2: 155.27\n",
      "[30]\tvalid_0's l2: 156.173\n",
      "[31]\tvalid_0's l2: 155.922\n",
      "[32]\tvalid_0's l2: 156.295\n",
      "[33]\tvalid_0's l2: 156.456\n",
      "[34]\tvalid_0's l2: 157.153\n",
      "[35]\tvalid_0's l2: 157.171\n",
      "[36]\tvalid_0's l2: 157.382\n",
      "[37]\tvalid_0's l2: 157.79\n",
      "[38]\tvalid_0's l2: 158.169\n",
      "[39]\tvalid_0's l2: 158.262\n",
      "[40]\tvalid_0's l2: 158.879\n",
      "[41]\tvalid_0's l2: 159.14\n",
      "[42]\tvalid_0's l2: 159.691\n",
      "[43]\tvalid_0's l2: 159.875\n",
      "[44]\tvalid_0's l2: 160.142\n",
      "[45]\tvalid_0's l2: 160.776\n",
      "[46]\tvalid_0's l2: 160.865\n",
      "[47]\tvalid_0's l2: 161.04\n",
      "[48]\tvalid_0's l2: 161.315\n",
      "[49]\tvalid_0's l2: 161.935\n",
      "[50]\tvalid_0's l2: 162.172\n",
      "[51]\tvalid_0's l2: 162.622\n",
      "[52]\tvalid_0's l2: 162.867\n",
      "[53]\tvalid_0's l2: 163.62\n",
      "[54]\tvalid_0's l2: 163.5\n",
      "[55]\tvalid_0's l2: 164.075\n",
      "[56]\tvalid_0's l2: 164.32\n",
      "[57]\tvalid_0's l2: 164.697\n",
      "[58]\tvalid_0's l2: 164.831\n",
      "[59]\tvalid_0's l2: 165.159\n",
      "[60]\tvalid_0's l2: 165.683\n",
      "[61]\tvalid_0's l2: 166.12\n",
      "[62]\tvalid_0's l2: 166.518\n",
      "[63]\tvalid_0's l2: 166.589\n",
      "[64]\tvalid_0's l2: 166.63\n",
      "[65]\tvalid_0's l2: 167.034\n",
      "[66]\tvalid_0's l2: 167.027\n",
      "[67]\tvalid_0's l2: 166.833\n",
      "[68]\tvalid_0's l2: 167.167\n",
      "[69]\tvalid_0's l2: 167.371\n",
      "[70]\tvalid_0's l2: 167.646\n",
      "[71]\tvalid_0's l2: 167.795\n",
      "[72]\tvalid_0's l2: 168.179\n",
      "[73]\tvalid_0's l2: 168.347\n",
      "[74]\tvalid_0's l2: 168.54\n",
      "[75]\tvalid_0's l2: 168.687\n",
      "[76]\tvalid_0's l2: 168.794\n",
      "[77]\tvalid_0's l2: 169.225\n",
      "[78]\tvalid_0's l2: 169.541\n",
      "[79]\tvalid_0's l2: 169.716\n",
      "[80]\tvalid_0's l2: 169.777\n",
      "[81]\tvalid_0's l2: 170.054\n",
      "[82]\tvalid_0's l2: 170.387\n",
      "[83]\tvalid_0's l2: 170.479\n",
      "[84]\tvalid_0's l2: 170.705\n",
      "[85]\tvalid_0's l2: 170.807\n",
      "[86]\tvalid_0's l2: 171.192\n",
      "[87]\tvalid_0's l2: 171.368\n",
      "[88]\tvalid_0's l2: 171.382\n",
      "[89]\tvalid_0's l2: 171.56\n",
      "[90]\tvalid_0's l2: 171.806\n",
      "[91]\tvalid_0's l2: 171.808\n",
      "[92]\tvalid_0's l2: 172.101\n",
      "[93]\tvalid_0's l2: 172.438\n",
      "[94]\tvalid_0's l2: 172.668\n",
      "[95]\tvalid_0's l2: 172.654\n",
      "[96]\tvalid_0's l2: 172.83\n",
      "[97]\tvalid_0's l2: 173.196\n",
      "[98]\tvalid_0's l2: 173.324\n",
      "[99]\tvalid_0's l2: 173.419\n",
      "[100]\tvalid_0's l2: 173.358\n",
      "[101]\tvalid_0's l2: 173.478\n",
      "[102]\tvalid_0's l2: 173.724\n",
      "[103]\tvalid_0's l2: 173.924\n",
      "[104]\tvalid_0's l2: 174.102\n",
      "[105]\tvalid_0's l2: 174.21\n",
      "[106]\tvalid_0's l2: 174.355\n",
      "[107]\tvalid_0's l2: 174.374\n",
      "[108]\tvalid_0's l2: 174.681\n",
      "[109]\tvalid_0's l2: 174.832\n",
      "[110]\tvalid_0's l2: 174.965\n",
      "[111]\tvalid_0's l2: 175.106\n",
      "[112]\tvalid_0's l2: 175.112\n",
      "[113]\tvalid_0's l2: 175.324\n",
      "[114]\tvalid_0's l2: 175.481\n",
      "[115]\tvalid_0's l2: 175.584\n",
      "[116]\tvalid_0's l2: 175.589\n",
      "[117]\tvalid_0's l2: 175.802\n",
      "[118]\tvalid_0's l2: 176.025\n",
      "[119]\tvalid_0's l2: 176.104\n",
      "[120]\tvalid_0's l2: 176.331\n",
      "[121]\tvalid_0's l2: 176.432\n",
      "[122]\tvalid_0's l2: 176.565\n",
      "[123]\tvalid_0's l2: 176.582\n",
      "[124]\tvalid_0's l2: 176.771\n",
      "[125]\tvalid_0's l2: 176.83\n",
      "[126]\tvalid_0's l2: 176.873\n",
      "[127]\tvalid_0's l2: 176.993\n",
      "[128]\tvalid_0's l2: 177.105\n",
      "[129]\tvalid_0's l2: 177.268\n",
      "[130]\tvalid_0's l2: 177.161\n",
      "[131]\tvalid_0's l2: 177.17\n",
      "[132]\tvalid_0's l2: 177.154\n",
      "[133]\tvalid_0's l2: 177.219\n",
      "[134]\tvalid_0's l2: 177.266\n",
      "[135]\tvalid_0's l2: 177.393\n",
      "[136]\tvalid_0's l2: 177.46\n",
      "[137]\tvalid_0's l2: 177.475\n",
      "[138]\tvalid_0's l2: 177.566\n",
      "[139]\tvalid_0's l2: 177.601\n",
      "[140]\tvalid_0's l2: 177.679\n",
      "[141]\tvalid_0's l2: 177.74\n",
      "[142]\tvalid_0's l2: 177.699\n",
      "[143]\tvalid_0's l2: 177.785\n",
      "[144]\tvalid_0's l2: 177.793\n",
      "[145]\tvalid_0's l2: 177.948\n",
      "[146]\tvalid_0's l2: 177.976\n",
      "[147]\tvalid_0's l2: 178.043\n",
      "[148]\tvalid_0's l2: 178.06\n",
      "[149]\tvalid_0's l2: 178.027\n",
      "[150]\tvalid_0's l2: 178.101\n",
      "[151]\tvalid_0's l2: 178.106\n",
      "[152]\tvalid_0's l2: 178.098\n",
      "[153]\tvalid_0's l2: 178.099\n",
      "[154]\tvalid_0's l2: 178.12\n",
      "[155]\tvalid_0's l2: 178.285\n",
      "[156]\tvalid_0's l2: 178.363\n",
      "[157]\tvalid_0's l2: 178.304\n",
      "[158]\tvalid_0's l2: 178.356\n",
      "[159]\tvalid_0's l2: 178.429\n",
      "[160]\tvalid_0's l2: 178.481\n",
      "[161]\tvalid_0's l2: 178.607\n",
      "[162]\tvalid_0's l2: 178.805\n",
      "[163]\tvalid_0's l2: 178.831\n",
      "[164]\tvalid_0's l2: 178.813\n",
      "[165]\tvalid_0's l2: 178.821\n",
      "[166]\tvalid_0's l2: 178.938\n",
      "[167]\tvalid_0's l2: 178.851\n",
      "[168]\tvalid_0's l2: 178.966\n",
      "[169]\tvalid_0's l2: 178.978\n",
      "[170]\tvalid_0's l2: 179.084\n",
      "[171]\tvalid_0's l2: 179.1\n",
      "[172]\tvalid_0's l2: 179.12\n",
      "[173]\tvalid_0's l2: 179.144\n",
      "[174]\tvalid_0's l2: 179.134\n",
      "[175]\tvalid_0's l2: 179.275\n",
      "[176]\tvalid_0's l2: 179.338\n",
      "[177]\tvalid_0's l2: 179.461\n",
      "[178]\tvalid_0's l2: 179.466\n",
      "[179]\tvalid_0's l2: 179.453\n",
      "[180]\tvalid_0's l2: 179.443\n",
      "[181]\tvalid_0's l2: 179.456\n",
      "[182]\tvalid_0's l2: 179.471\n",
      "[183]\tvalid_0's l2: 179.52\n",
      "[184]\tvalid_0's l2: 179.652\n",
      "[185]\tvalid_0's l2: 179.678\n",
      "[186]\tvalid_0's l2: 179.666\n",
      "[187]\tvalid_0's l2: 179.629\n",
      "[188]\tvalid_0's l2: 179.638\n",
      "[189]\tvalid_0's l2: 179.671\n",
      "[190]\tvalid_0's l2: 179.621\n",
      "[191]\tvalid_0's l2: 179.591\n",
      "[192]\tvalid_0's l2: 179.708\n",
      "[193]\tvalid_0's l2: 179.718\n",
      "[194]\tvalid_0's l2: 179.752\n",
      "[195]\tvalid_0's l2: 179.79\n",
      "[196]\tvalid_0's l2: 179.865\n",
      "[197]\tvalid_0's l2: 179.893\n",
      "[198]\tvalid_0's l2: 179.932\n",
      "[199]\tvalid_0's l2: 179.95\n",
      "[200]\tvalid_0's l2: 179.977\n",
      "5.62Minutes in Split Number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelkshake\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 259.471\n",
      "[2]\tvalid_0's l2: 238.302\n",
      "[3]\tvalid_0's l2: 221.038\n",
      "[4]\tvalid_0's l2: 208.125\n",
      "[5]\tvalid_0's l2: 195.546\n",
      "[6]\tvalid_0's l2: 185.298\n",
      "[7]\tvalid_0's l2: 177.218\n",
      "[8]\tvalid_0's l2: 170.458\n",
      "[9]\tvalid_0's l2: 165.489\n",
      "[10]\tvalid_0's l2: 160.113\n",
      "[11]\tvalid_0's l2: 156.042\n",
      "[12]\tvalid_0's l2: 152.432\n",
      "[13]\tvalid_0's l2: 150.445\n",
      "[14]\tvalid_0's l2: 148.745\n",
      "[15]\tvalid_0's l2: 147.644\n",
      "[16]\tvalid_0's l2: 146.158\n",
      "[17]\tvalid_0's l2: 145.393\n",
      "[18]\tvalid_0's l2: 145.481\n",
      "[19]\tvalid_0's l2: 144.755\n",
      "[20]\tvalid_0's l2: 143.987\n",
      "[21]\tvalid_0's l2: 143.681\n",
      "[22]\tvalid_0's l2: 143.552\n",
      "[23]\tvalid_0's l2: 142.83\n",
      "[24]\tvalid_0's l2: 142.481\n",
      "[25]\tvalid_0's l2: 143.053\n",
      "[26]\tvalid_0's l2: 142.72\n",
      "[27]\tvalid_0's l2: 142.672\n",
      "[28]\tvalid_0's l2: 142.51\n",
      "[29]\tvalid_0's l2: 142.261\n",
      "[30]\tvalid_0's l2: 142.007\n",
      "[31]\tvalid_0's l2: 141.609\n",
      "[32]\tvalid_0's l2: 141.74\n",
      "[33]\tvalid_0's l2: 141.523\n",
      "[34]\tvalid_0's l2: 141.541\n",
      "[35]\tvalid_0's l2: 141.3\n",
      "[36]\tvalid_0's l2: 141.005\n",
      "[37]\tvalid_0's l2: 141.233\n",
      "[38]\tvalid_0's l2: 141.809\n",
      "[39]\tvalid_0's l2: 142.054\n",
      "[40]\tvalid_0's l2: 141.951\n",
      "[41]\tvalid_0's l2: 142.289\n",
      "[42]\tvalid_0's l2: 142.273\n",
      "[43]\tvalid_0's l2: 142.485\n",
      "[44]\tvalid_0's l2: 142.18\n",
      "[45]\tvalid_0's l2: 142.382\n",
      "[46]\tvalid_0's l2: 142.373\n",
      "[47]\tvalid_0's l2: 142.303\n",
      "[48]\tvalid_0's l2: 142.835\n",
      "[49]\tvalid_0's l2: 143.01\n",
      "[50]\tvalid_0's l2: 142.788\n",
      "[51]\tvalid_0's l2: 143.022\n",
      "[52]\tvalid_0's l2: 143.518\n",
      "[53]\tvalid_0's l2: 143.676\n",
      "[54]\tvalid_0's l2: 143.532\n",
      "[55]\tvalid_0's l2: 143.615\n",
      "[56]\tvalid_0's l2: 143.87\n",
      "[57]\tvalid_0's l2: 143.819\n",
      "[58]\tvalid_0's l2: 143.82\n",
      "[59]\tvalid_0's l2: 143.9\n",
      "[60]\tvalid_0's l2: 144.211\n",
      "[61]\tvalid_0's l2: 144.641\n",
      "[62]\tvalid_0's l2: 144.797\n",
      "[63]\tvalid_0's l2: 145.041\n",
      "[64]\tvalid_0's l2: 145.216\n",
      "[65]\tvalid_0's l2: 145.494\n",
      "[66]\tvalid_0's l2: 145.787\n",
      "[67]\tvalid_0's l2: 145.826\n",
      "[68]\tvalid_0's l2: 145.821\n",
      "[69]\tvalid_0's l2: 146.221\n",
      "[70]\tvalid_0's l2: 146.253\n",
      "[71]\tvalid_0's l2: 146.483\n",
      "[72]\tvalid_0's l2: 146.549\n",
      "[73]\tvalid_0's l2: 146.615\n",
      "[74]\tvalid_0's l2: 146.856\n",
      "[75]\tvalid_0's l2: 146.826\n",
      "[76]\tvalid_0's l2: 146.879\n",
      "[77]\tvalid_0's l2: 146.79\n",
      "[78]\tvalid_0's l2: 146.946\n",
      "[79]\tvalid_0's l2: 147.055\n",
      "[80]\tvalid_0's l2: 147.386\n",
      "[81]\tvalid_0's l2: 147.521\n",
      "[82]\tvalid_0's l2: 147.505\n",
      "[83]\tvalid_0's l2: 147.577\n",
      "[84]\tvalid_0's l2: 147.7\n",
      "[85]\tvalid_0's l2: 147.795\n",
      "[86]\tvalid_0's l2: 147.755\n",
      "[87]\tvalid_0's l2: 147.959\n",
      "[88]\tvalid_0's l2: 148.012\n",
      "[89]\tvalid_0's l2: 148.18\n",
      "[90]\tvalid_0's l2: 148.22\n",
      "[91]\tvalid_0's l2: 148.329\n",
      "[92]\tvalid_0's l2: 148.39\n",
      "[93]\tvalid_0's l2: 148.642\n",
      "[94]\tvalid_0's l2: 148.722\n",
      "[95]\tvalid_0's l2: 148.773\n",
      "[96]\tvalid_0's l2: 148.766\n",
      "[97]\tvalid_0's l2: 148.933\n",
      "[98]\tvalid_0's l2: 149.029\n",
      "[99]\tvalid_0's l2: 149.146\n",
      "[100]\tvalid_0's l2: 149.169\n",
      "[101]\tvalid_0's l2: 149.142\n",
      "[102]\tvalid_0's l2: 149.117\n",
      "[103]\tvalid_0's l2: 149.094\n",
      "[104]\tvalid_0's l2: 148.982\n",
      "[105]\tvalid_0's l2: 148.83\n",
      "[106]\tvalid_0's l2: 148.85\n",
      "[107]\tvalid_0's l2: 148.856\n",
      "[108]\tvalid_0's l2: 148.956\n",
      "[109]\tvalid_0's l2: 149.048\n",
      "[110]\tvalid_0's l2: 149.033\n",
      "[111]\tvalid_0's l2: 149.146\n",
      "[112]\tvalid_0's l2: 149.284\n",
      "[113]\tvalid_0's l2: 149.354\n",
      "[114]\tvalid_0's l2: 149.475\n",
      "[115]\tvalid_0's l2: 149.512\n",
      "[116]\tvalid_0's l2: 149.53\n",
      "[117]\tvalid_0's l2: 149.558\n",
      "[118]\tvalid_0's l2: 149.641\n",
      "[119]\tvalid_0's l2: 149.762\n",
      "[120]\tvalid_0's l2: 149.863\n",
      "[121]\tvalid_0's l2: 149.83\n",
      "[122]\tvalid_0's l2: 149.973\n",
      "[123]\tvalid_0's l2: 150.123\n",
      "[124]\tvalid_0's l2: 150.204\n",
      "[125]\tvalid_0's l2: 150.234\n",
      "[126]\tvalid_0's l2: 150.228\n",
      "[127]\tvalid_0's l2: 150.349\n",
      "[128]\tvalid_0's l2: 150.471\n",
      "[129]\tvalid_0's l2: 150.48\n",
      "[130]\tvalid_0's l2: 150.584\n",
      "[131]\tvalid_0's l2: 150.641\n",
      "[132]\tvalid_0's l2: 150.677\n",
      "[133]\tvalid_0's l2: 150.74\n",
      "[134]\tvalid_0's l2: 150.755\n",
      "[135]\tvalid_0's l2: 150.672\n",
      "[136]\tvalid_0's l2: 150.704\n",
      "[137]\tvalid_0's l2: 150.748\n",
      "[138]\tvalid_0's l2: 150.836\n",
      "[139]\tvalid_0's l2: 150.932\n",
      "[140]\tvalid_0's l2: 150.897\n",
      "[141]\tvalid_0's l2: 150.932\n",
      "[142]\tvalid_0's l2: 150.976\n",
      "[143]\tvalid_0's l2: 151.02\n",
      "[144]\tvalid_0's l2: 151.068\n",
      "[145]\tvalid_0's l2: 151.08\n",
      "[146]\tvalid_0's l2: 151.04\n",
      "[147]\tvalid_0's l2: 151.129\n",
      "[148]\tvalid_0's l2: 151.208\n",
      "[149]\tvalid_0's l2: 151.206\n",
      "[150]\tvalid_0's l2: 151.212\n",
      "[151]\tvalid_0's l2: 151.236\n",
      "[152]\tvalid_0's l2: 151.216\n",
      "[153]\tvalid_0's l2: 151.316\n",
      "[154]\tvalid_0's l2: 151.335\n",
      "[155]\tvalid_0's l2: 151.343\n",
      "[156]\tvalid_0's l2: 151.394\n",
      "[157]\tvalid_0's l2: 151.339\n",
      "[158]\tvalid_0's l2: 151.342\n",
      "[159]\tvalid_0's l2: 151.41\n",
      "[160]\tvalid_0's l2: 151.378\n",
      "[161]\tvalid_0's l2: 151.39\n",
      "[162]\tvalid_0's l2: 151.417\n",
      "[163]\tvalid_0's l2: 151.498\n",
      "[164]\tvalid_0's l2: 151.457\n",
      "[165]\tvalid_0's l2: 151.549\n",
      "[166]\tvalid_0's l2: 151.535\n",
      "[167]\tvalid_0's l2: 151.477\n",
      "[168]\tvalid_0's l2: 151.488\n",
      "[169]\tvalid_0's l2: 151.515\n",
      "[170]\tvalid_0's l2: 151.52\n",
      "[171]\tvalid_0's l2: 151.5\n",
      "[172]\tvalid_0's l2: 151.515\n",
      "[173]\tvalid_0's l2: 151.54\n",
      "[174]\tvalid_0's l2: 151.606\n",
      "[175]\tvalid_0's l2: 151.575\n",
      "[176]\tvalid_0's l2: 151.622\n",
      "[177]\tvalid_0's l2: 151.691\n",
      "[178]\tvalid_0's l2: 151.693\n",
      "[179]\tvalid_0's l2: 151.682\n",
      "[180]\tvalid_0's l2: 151.784\n",
      "[181]\tvalid_0's l2: 151.76\n",
      "[182]\tvalid_0's l2: 151.769\n",
      "[183]\tvalid_0's l2: 151.756\n",
      "[184]\tvalid_0's l2: 151.921\n",
      "[185]\tvalid_0's l2: 151.953\n",
      "[186]\tvalid_0's l2: 152.045\n",
      "[187]\tvalid_0's l2: 152.083\n",
      "[188]\tvalid_0's l2: 152.104\n",
      "[189]\tvalid_0's l2: 152.086\n",
      "[190]\tvalid_0's l2: 152.131\n",
      "[191]\tvalid_0's l2: 152.148\n",
      "[192]\tvalid_0's l2: 152.124\n",
      "[193]\tvalid_0's l2: 152.16\n",
      "[194]\tvalid_0's l2: 152.148\n",
      "[195]\tvalid_0's l2: 152.202\n",
      "[196]\tvalid_0's l2: 152.201\n",
      "[197]\tvalid_0's l2: 152.226\n",
      "[198]\tvalid_0's l2: 152.217\n",
      "[199]\tvalid_0's l2: 152.177\n",
      "[200]\tvalid_0's l2: 152.181\n",
      "4.81Minutes in Split Number: 4\n"
     ]
    }
   ],
   "source": [
    "#Cross-Validation\n",
    "mse_lwr_d = []\n",
    "mse_lwr_rf = []\n",
    "mse_rf_d = []\n",
    "mse_lwr_lwr = []\n",
    "mse_lgbm = []\n",
    "\n",
    "scale = StandardScaler()\n",
    "for i in range(12345,12346):\n",
    "  print('Random State: ' + str(i))\n",
    "  kf = KFold(n_splits=10,shuffle=True,random_state=i)\n",
    "  # this is the random state cross-validation loop to make sure our results are real, not just the state being good/bad for a particular model\n",
    "  j = 0\n",
    "  for idxtrain, idxtest in kf.split(data[:,:2]):\n",
    "    t = time.time()\n",
    "    j += 1\n",
    "    #Split the train and test data\n",
    "    xtrain = data[:,:6][idxtrain]\n",
    "    ytrain = data[:,-1][idxtrain]\n",
    "    ytest = data[:,-1][idxtest]\n",
    "    xtest = data[:,:6][idxtest]\n",
    "    xtrain = scale.fit_transform(xtrain)\n",
    "    xtest = scale.transform(xtest)\n",
    "\n",
    "\n",
    "    #LWR boosted with decision tree\n",
    "    booster = DecisionTreeRegressor(max_depth=2)\n",
    "    yhat_lwr_d = n_boost(xtrain, ytrain, xtest, model = 'LWR', nboost=3, booster=booster, \n",
    "                   kern = Tricubic, tau = 1.2, intercept = True,)\n",
    "    \n",
    "    #LWR boosted with RF\n",
    "    booster = RandomForestRegressor(n_estimators=25, max_depth=2)\n",
    "    yhat_lwr_rf = n_boost(xtrain, ytrain, xtest, model = 'LWR', nboost=3, booster=booster, \n",
    "                   kern = Tricubic, tau = 1.2, intercept = True)\n",
    "\n",
    "    #LWR boosted with LWR\n",
    "    booster='LWR'\n",
    "    yhat_lwr_lwr = n_boost(xtrain, ytrain, xtest, model = 'LWR', nboost=3, booster=booster, \n",
    "                   kern = Tricubic, tau = 1.2, tau_b=0.5, intercept = True)\n",
    "    \n",
    "    #RF boosted with decision tree\n",
    "    booster = DecisionTreeRegressor(max_depth=2)\n",
    "    yhat_rf_d = n_boost(xtrain, ytrain, xtest, model = 'RFR', nboost=3, booster=booster, n_estimators=100 , max_depth=3)\n",
    "    \n",
    "    #RF boosted with LWR\n",
    "    booster = 'LWR'\n",
    "    yhat_rf_d = n_boost(xtrain, ytrain, xtest, model = 'RFR', nboost=3, booster=booster, \n",
    "                   kern = Tricubic, tau = 1.2, tau_b=0.5, intercept = True, n_estimators=100 , max_depth=3)\n",
    "\n",
    "    #LightGBM\n",
    "    lgb = lgbm.LGBMRegressor(num_iterations=200)\n",
    "    lgb.fit(xtrain, ytrain, eval_set=[(xtest, ytest)], eval_metric='mse')\n",
    "    yhat_lgbm = lgb.predict(xtest, num_iteration=lgb.best_iteration_)\n",
    "\n",
    "\n",
    "    #Append each model's MSE\n",
    "    mse_lwr_lwr.append(mse(ytest,yhat_lwr_lwr))\n",
    "    mse_lwr_d.append(mse(ytest,yhat_lwr_d))\n",
    "    mse_lwr_rf.append(mse(ytest,yhat_lwr_rf))\n",
    "    mse_rf_d.append(mse(ytest,yhat_rf_d))\n",
    "    mse_lgbm.append(mse(ytest,yhat_lgbm))\n",
    "\n",
    "    dt = time.time() - t\n",
    "    print(str(np.around(dt/60, 2)) + 'Minutes in Split Number: ' + str(j))\n",
    "    \n",
    "\n",
    "print('\\n The Results for the Concrete Compressive Strength Dataset were:')\n",
    "print('The Cross-validated Mean Squared Error for LWR with Decision Tree is : '+str(np.mean(mse_lwr_d)))\n",
    "print('The Cross-validated Mean Squared Error for LWR with Random Forest is : '+str(np.mean(mse_lwr_rf)))\n",
    "print('The Cross-validated Mean Squared Error for Random Forest with Decision Tree is : '+str(np.mean(mse_rf_d)))\n",
    "print('The Cross-validated Mean Squared Error for LWR with LWR : '+str(np.mean(mse_lwr_lwr)))\n",
    "print('The Cross-validated Mean Squared Error for LightGBM : '+str(np.mean(mse_lgbm)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb8b7f83ee360ab7c65e3bf584de3c309f966a927bbfa0413b48c366d5d9edbf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
