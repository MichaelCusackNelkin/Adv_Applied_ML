{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lVibhQJNBpVx"
      },
      "outputs": [],
      "source": [
        "#! pip install statsmodels==0.13.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tzI8diQStGK_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.linalg import lstsq\n",
        "from scipy.sparse.linalg import lsmr\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split as tts\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cQDY8BwdBcQV"
      },
      "outputs": [],
      "source": [
        "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
        "\n",
        "# reference for the Nadaraya-Watson regressor: https://bookdown.org/egarpor/PM-UC3M/npreg-kre.html\n",
        "\n",
        "#model_KernReg = KernelReg(endog=dat_train[:,-1],exog=dat_train[:,:-1],var_type='ccc',ckertype='gaussian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U5FAHUXH7jLq"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lightgbm'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29912/900739321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_orc85rLtP-z"
      },
      "outputs": [],
      "source": [
        "# import libraries for creating a neural network\n",
        "# imports for creating a Neural Network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop # they recently updated Tensorflow\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5HBdXpldtrcX"
      },
      "outputs": [],
      "source": [
        "# Tricubic Kernel\n",
        "def Tricubic(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,70/81*(1-d**3)**3)\n",
        "\n",
        "# Quartic Kernel\n",
        "def Quartic(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,15/16*(1-d**2)**2)\n",
        "\n",
        "# Epanechnikov Kernel\n",
        "def Epanechnikov(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,3/4*(1-d**2)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "okWUm6dLtsCx"
      },
      "outputs": [],
      "source": [
        "#Defining the kernel local regression model\n",
        "\n",
        "def lw_reg(X, y, xnew, kern, tau, intercept):\n",
        "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
        "    n = len(X) # the number of observations\n",
        "    yest = np.zeros(n)\n",
        "\n",
        "    if len(y.shape)==1: # here we make column vectors\n",
        "      y = y.reshape(-1,1)\n",
        "\n",
        "    if len(X.shape)==1:\n",
        "      X = X.reshape(-1,1)\n",
        "    \n",
        "    if intercept:\n",
        "      X1 = np.column_stack([np.ones((len(X),1)),X])\n",
        "    else:\n",
        "      X1 = X\n",
        "\n",
        "    w = np.array([kern((X - X[i])/(2*tau)) for i in range(n)]) # here we compute n vectors of weights\n",
        "\n",
        "    #Looping through all X-points\n",
        "    for i in range(n):          \n",
        "        W = np.diag(w[:,i])\n",
        "        b = np.transpose(X1).dot(W).dot(y)\n",
        "        A = np.transpose(X1).dot(W).dot(X1)\n",
        "        #A = A + 0.001*np.eye(X1.shape[1]) # if we want L2 regularization\n",
        "        #theta = linalg.solve(A, b) # A*theta = b\n",
        "        beta, res, rnk, s = lstsq(A, b)\n",
        "        yest[i] = np.dot(X1[i],beta)\n",
        "    if X.shape[1]==1:\n",
        "      f = interp1d(X.flatten(),yest,fill_value='extrapolate')\n",
        "    else:\n",
        "      f = LinearNDInterpolator(X, yest)\n",
        "    output = f(xnew) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "    if sum(np.isnan(output))>0:\n",
        "      g = NearestNDInterpolator(X,y.ravel()) \n",
        "      # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
        "      output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AavQi1Ectw0O"
      },
      "outputs": [],
      "source": [
        "def boosted_lwr(X, y, xnew, kern, tau, intercept):\n",
        "  # we need decision trees\n",
        "  # for training the boosted method we use X and y\n",
        "  Fx = lw_reg(X,y,X,kern,tau,intercept) # we need this for training the Decision Tree\n",
        "  # Now train the Decision Tree on y_i - F(x_i)\n",
        "  new_y = y - Fx\n",
        "  #model = DecisionTreeRegressor(max_depth=2, random_state=123)\n",
        "  model = RandomForestRegressor(n_estimators=100,max_depth=2)\n",
        "  #model = model_xgb\n",
        "  model.fit(X,new_y)\n",
        "  output = model.predict(xnew) + lw_reg(X,y,xnew,kern,tau,intercept)\n",
        "  return output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "svDUqbcZt3bR"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-ZKq9_GXt_pX"
      },
      "outputs": [],
      "source": [
        "# we design a Neural Network for regression\n",
        "# We have to decide how many layers we want, how many neurons per layer and the type of activation functions\n",
        "# Create a Neural Network model\n",
        "model_nn = Sequential()\n",
        "model_nn.add(Dense(128, activation=\"relu\", input_dim=3))\n",
        "model_nn.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "# Since the regression is performed, a Dense layer containing a single neuron with a linear activation function.\n",
        "# Typically ReLu-based activation are used but since it is performed regression, it is needed a linear activation.\n",
        "model_nn.add(Dense(1, activation=\"linear\")) # we need this b/c we predict a continuous random variable\n",
        "\n",
        "# Compile model: The model is initialized with the Adam optimizer and then it is compiled.\n",
        "model_nn.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=1e-2)) # lr=1e-3, decay=1e-3 / 200)\n",
        "\n",
        "# Patient early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g50XPWtzw8AE"
      },
      "outputs": [],
      "source": [
        "# import the data\n",
        "cars = pd.read_csv('Data/cars.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3eCytX9zyT_q"
      },
      "outputs": [],
      "source": [
        "X = cars[['ENG','CYL','WGT']].values\n",
        "y = cars['MPG'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "whhtyY1iyjQP"
      },
      "outputs": [],
      "source": [
        "scale = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N4i5EEGxC1_A"
      },
      "outputs": [],
      "source": [
        "dat = np.concatenate([X,y.reshape(-1,1)],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5n7Oo5uXDb3p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18.      , 15.      , 18.      , 16.      , 17.      , 15.      ,\n",
              "       14.      , 14.      , 14.      , 15.      , 15.      , 14.      ,\n",
              "       15.      , 14.      , 24.      , 22.      , 18.      , 21.      ,\n",
              "       27.      , 26.      , 25.      , 24.      , 25.      , 26.      ,\n",
              "       21.      , 10.      , 10.      , 11.      ,  9.      , 27.      ,\n",
              "       28.      , 25.      , 19.      , 16.      , 17.      , 19.      ,\n",
              "       18.      , 14.      , 14.      , 14.      , 14.      , 12.      ,\n",
              "       13.      , 13.      , 18.      , 22.      , 19.      , 18.      ,\n",
              "       23.      , 28.      , 30.      , 30.      , 31.      , 35.      ,\n",
              "       27.      , 26.      , 24.      , 25.      , 23.      , 20.      ,\n",
              "       21.      , 13.      , 14.      , 15.      , 14.      , 17.      ,\n",
              "       11.      , 13.      , 12.      , 13.      , 19.      , 15.      ,\n",
              "       13.      , 13.      , 14.      , 18.      , 22.      , 21.      ,\n",
              "       26.      , 22.      , 28.      , 23.      , 28.      , 27.      ,\n",
              "       13.      , 14.      , 13.      , 14.      , 15.      , 12.      ,\n",
              "       13.      , 13.      , 14.      , 13.      , 12.      , 13.      ,\n",
              "       18.      , 16.      , 18.      , 18.      , 23.      , 26.      ,\n",
              "       11.      , 12.      , 13.      , 12.      , 18.      , 20.      ,\n",
              "       21.      , 22.      , 18.      , 19.      , 21.      , 26.      ,\n",
              "       15.      , 16.      , 29.      , 24.      , 20.      , 19.      ,\n",
              "       15.      , 24.      , 20.      , 11.      , 20.      , 19.      ,\n",
              "       15.      , 31.      , 26.      , 32.      , 25.      , 16.      ,\n",
              "       16.      , 18.      , 16.      , 13.      , 14.      , 14.      ,\n",
              "       14.      , 29.      , 26.      , 26.      , 31.      , 32.      ,\n",
              "       28.      , 24.      , 26.      , 24.      , 26.      , 31.      ,\n",
              "       19.      , 18.      , 15.      , 15.      , 16.      , 15.      ,\n",
              "       16.      , 14.      , 17.      , 16.      , 15.      , 18.      ,\n",
              "       21.      , 20.      , 13.      , 29.      , 23.      , 20.      ,\n",
              "       23.      , 24.      , 25.      , 24.      , 18.      , 29.      ,\n",
              "       19.      , 23.      , 23.      , 22.      , 25.      , 33.      ,\n",
              "       28.      , 25.      , 25.      , 26.      , 27.      , 17.5     ,\n",
              "       16.      , 15.5     , 14.5     , 22.      , 22.      , 24.      ,\n",
              "       22.5     , 29.      , 24.5     , 29.      , 33.      , 20.      ,\n",
              "       18.      , 18.5     , 17.5     , 29.5     , 32.      , 28.      ,\n",
              "       26.5     , 20.      , 13.      , 19.      , 19.      , 16.5     ,\n",
              "       16.5     , 13.      , 13.      , 13.      , 31.5     , 30.      ,\n",
              "       36.      , 25.5     , 33.5     , 17.5     , 17.      , 15.5     ,\n",
              "       15.      , 17.5     , 20.5     , 19.      , 18.5     , 16.      ,\n",
              "       15.5     , 15.5     , 16.      , 29.      , 24.5     , 26.      ,\n",
              "       25.5     , 30.5     , 33.5     , 30.      , 30.5     , 22.      ,\n",
              "       21.5     , 21.5     , 43.099998, 36.099998, 32.799999, 39.400002,\n",
              "       36.099998, 19.9     , 19.4     , 20.200001, 19.200001, 20.5     ,\n",
              "       20.200001, 25.1     , 20.5     , 19.4     , 20.6     , 20.799999,\n",
              "       18.6     , 18.1     , 19.200001, 17.700001, 18.1     , 17.5     ,\n",
              "       30.      , 27.5     , 27.200001, 30.9     , 21.1     , 23.200001,\n",
              "       23.799999, 23.9     , 20.299999, 17.      , 21.6     , 16.200001,\n",
              "       31.5     , 29.5     , 21.5     , 19.799999, 22.299999, 20.200001,\n",
              "       20.6     , 17.      , 17.6     , 16.5     , 18.200001, 16.9     ,\n",
              "       15.5     , 19.200001, 18.5     , 31.9     , 34.099998, 35.700001,\n",
              "       27.4     , 25.4     , 23.      , 27.200001, 23.9     , 34.200001,\n",
              "       34.5     , 31.799999, 37.299999, 28.4     , 28.799999, 26.799999,\n",
              "       33.5     , 41.5     , 38.099998, 32.099998, 37.200001, 28.      ,\n",
              "       26.4     , 24.299999, 19.1     , 34.299999, 29.799999, 31.299999,\n",
              "       37.      , 32.200001, 46.599998, 27.9     , 40.799999, 44.299999,\n",
              "       43.400002, 36.400002, 30.      , 44.599998, 33.799999, 29.799999,\n",
              "       32.700001, 23.700001, 35.      , 32.400002, 27.200001, 26.6     ,\n",
              "       25.799999, 23.5     , 30.      , 39.099998, 39.      , 35.099998,\n",
              "       32.299999, 37.      , 37.700001, 34.099998, 34.700001, 34.400002,\n",
              "       29.9     , 33.      , 33.700001, 32.400002, 32.900002, 31.6     ,\n",
              "       28.1     , 30.700001, 25.4     , 24.200001, 22.4     , 26.6     ,\n",
              "       20.200001, 17.6     , 28.      , 27.      , 34.      , 31.      ,\n",
              "       29.      , 27.      , 24.      , 36.      , 37.      , 31.      ,\n",
              "       38.      , 36.      , 36.      , 36.      , 34.      , 38.      ,\n",
              "       32.      , 38.      , 25.      , 38.      , 26.      , 22.      ,\n",
              "       32.      , 36.      , 27.      , 27.      , 44.      , 32.      ,\n",
              "       28.      , 31.      ])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat[:,-1] # this is the y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l6uclKI6Dny0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 307.,    8., 3504.],\n",
              "       [ 350.,    8., 3693.],\n",
              "       [ 318.,    8., 3436.],\n",
              "       ...,\n",
              "       [ 135.,    4., 2295.],\n",
              "       [ 120.,    4., 2625.],\n",
              "       [ 119.,    4., 2720.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat[:,:-1] # this is X values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4U_X6eNFDG54"
      },
      "outputs": [],
      "source": [
        "model_KernReg = KernelReg(endog=dat[:,-1],exog=dat[:,:-1],var_type='ccc',ckertype='gaussian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RkSOTHBGEf_m"
      },
      "outputs": [],
      "source": [
        "yhat_sm, y_std = model_KernReg.fit(dat[:,:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4LeGT0lEnb5",
        "outputId": "6fd803fd-927d-422c-b1c8-081f2dbac3e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.333316197606733"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse(y,yhat_sm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PiQhS7GZAXOm",
        "outputId": "fa4e0b28-89fe-463a-d1d3-efcdffdc8b6b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29912/2758047925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0myhat_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mmodel_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0myhat_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# here is the application of the N-W regressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1252\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1529\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m             \"not be specified.\")\n\u001b[1;32m--> 726\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    749\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 751\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3235\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3236\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3237\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3238\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we want more nested cross-validations\n",
        "\n",
        "mse_lwr = []\n",
        "mse_blwr = []\n",
        "mse_rf = []\n",
        "mse_xgb = []\n",
        "mse_nn = []\n",
        "mse_NW = []\n",
        "for i in [1234]:\n",
        "  kf = KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "  # this is the Cross-Validation Loop\n",
        "  for idxtrain, idxtest in kf.split(X):\n",
        "    xtrain = X[idxtrain]\n",
        "    ytrain = y[idxtrain]\n",
        "    ytest = y[idxtest]\n",
        "    xtest = X[idxtest]\n",
        "    xtrain = scale.fit_transform(xtrain)\n",
        "    xtest = scale.transform(xtest)\n",
        "    dat_train = np.concatenate([xtrain,ytrain.reshape(-1,1)],axis=1)\n",
        "    dat_test = np.concatenate([xtest,ytest.reshape(-1,1)],axis=1)\n",
        "    yhat_lwr = lw_reg(xtrain,ytrain, xtest,Epanechnikov,tau=0.9,intercept=True)\n",
        "    yhat_blwr = boosted_lwr(xtrain,ytrain, xtest,Epanechnikov,tau=0.9,intercept=True)\n",
        "    model_rf = RandomForestRegressor(n_estimators=100,max_depth=3)\n",
        "    model_rf.fit(xtrain,ytrain)\n",
        "    yhat_rf = model_rf.predict(xtest)\n",
        "    model_xgb = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=3)\n",
        "    model_xgb.fit(xtrain,ytrain)\n",
        "    yhat_xgb = model_xgb.predict(xtest)\n",
        "    model_nn.fit(xtrain,ytrain,validation_split=0.2, epochs=500, batch_size=10, verbose=0, callbacks=[es])\n",
        "    yhat_nn = model_nn.predict(xtest)\n",
        "    # here is the application of the N-W regressor\n",
        "    model_KernReg = KernelReg(endog=dat_train[:,-1],exog=dat_train[:,:-1],var_type='ccc',ckertype='gaussian')\n",
        "    yhat_sm, yhat_std = model_KernReg.fit(dat_test[:,:-1])\n",
        "    mse_lwr.append(mse(ytest,yhat_lwr))\n",
        "    mse_blwr.append(mse(ytest,yhat_blwr))\n",
        "    mse_rf.append(mse(ytest,yhat_rf))\n",
        "    mse_xgb.append(mse(ytest,yhat_xgb))\n",
        "    mse_nn.append(mse(ytest,yhat_nn))\n",
        "    mse_NW.append(mse(ytest,yhat_sm))\n",
        "print('The Cross-validated Mean Squared Error for LWR is : '+str(np.mean(mse_lwr)))\n",
        "print('The Cross-validated Mean Squared Error for BLWR is : '+str(np.mean(mse_blwr)))\n",
        "print('The Cross-validated Mean Squared Error for RF is : '+str(np.mean(mse_rf)))\n",
        "print('The Cross-validated Mean Squared Error for XGB is : '+str(np.mean(mse_xgb)))\n",
        "print('The Cross-validated Mean Squared Error for NN is : '+str(np.mean(mse_nn)))\n",
        "print('The Cross-validated Mean Squared Error for Nadarya-Watson Regressor is : '+str(np.mean(mse_NW)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On_c8MKSySbp"
      },
      "outputs": [],
      "source": [
        "# apply this setup to the Boston Housing data set and also the Concrete Strength"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeated Boosting\n",
        "Update the algorithms we have for repeated boosting.\n",
        "Compare with more boosting algorithms such as LightGBM (and, time allows, Catboost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DATA 410 Active Coding Feb 23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
