{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "XFqyFVhL4LKQ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 120\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47zhKygt16DR"
      },
      "source": [
        "##<font color='navy' face='arial' size=12pt>More Applications with NLP</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jGLmCiMI_sg"
      },
      "source": [
        "## Application to wine ratings based on customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUtoy0hQI_Io",
        "outputId": "3dafefce-c4d6-4d9c-c0c6-66aa60964d19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\mnelk\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#!pip install nltk\n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# For stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#import CountVectorizer if we just want a Bag of Words Model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score as AC, confusion_matrix as CM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wa2RNx6S5Iem"
      },
      "outputs": [],
      "source": [
        "wine_data = pd.read_csv('Data/winemagdata130kv2.csv',quoting=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "HhRwhknM5cN4",
        "outputId": "05abca1c-da81-4135-88a3-4a684024b021"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>country</th>\n",
              "      <th>description</th>\n",
              "      <th>designation</th>\n",
              "      <th>points</th>\n",
              "      <th>price</th>\n",
              "      <th>province</th>\n",
              "      <th>region_1</th>\n",
              "      <th>region_2</th>\n",
              "      <th>taster_name</th>\n",
              "      <th>taster_twitter_handle</th>\n",
              "      <th>title</th>\n",
              "      <th>variety</th>\n",
              "      <th>winery</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
              "      <td>Vulkà Bianco</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sicily &amp; Sardinia</td>\n",
              "      <td>Etna</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kerin O’Keefe</td>\n",
              "      <td>@kerinokeefe</td>\n",
              "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
              "      <td>White Blend</td>\n",
              "      <td>Nicosia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
              "      <td>Avidagos</td>\n",
              "      <td>87.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Douro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
              "      <td>Portuguese Red</td>\n",
              "      <td>Quinta dos Avidagos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   country                                        description  \\\n",
              "0         0.0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
              "1         1.0  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
              "\n",
              "    designation  points  price           province region_1 region_2  \\\n",
              "0  Vulkà Bianco    87.0    NaN  Sicily & Sardinia     Etna      NaN   \n",
              "1      Avidagos    87.0   15.0              Douro      NaN      NaN   \n",
              "\n",
              "     taster_name taster_twitter_handle  \\\n",
              "0  Kerin O’Keefe          @kerinokeefe   \n",
              "1     Roger Voss            @vossroger   \n",
              "\n",
              "                                           title         variety  \\\n",
              "0              Nicosia 2013 Vulkà Bianco  (Etna)     White Blend   \n",
              "1  Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
              "\n",
              "                winery  \n",
              "0              Nicosia  \n",
              "1  Quinta dos Avidagos  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0         Aromas include tropical fruit, broom, brimston...\n",
              "1         This is ripe and fruity, a wine that is smooth...\n",
              "2         Tart and snappy, the flavors of lime flesh and...\n",
              "3         Pineapple rind, lemon pith and orange blossom ...\n",
              "4         Much like the regular bottling from 2012, this...\n",
              "                                ...                        \n",
              "129966    Notes of honeysuckle and cantaloupe sweeten th...\n",
              "129967    Citation is given as much as a decade of bottl...\n",
              "129968    Well-drained gravel soil gives this wine its c...\n",
              "129969    A dry style of Pinot Gris, this is crisp with ...\n",
              "129970    Big, rich and off-dry, this is powered by inte...\n",
              "Name: description, Length: 129971, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(wine_data.head(2))\n",
        "display(wine_data.description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RTvhQNjEQbVw",
        "outputId": "1415895b-9839-4877-c4af-0737e218ef55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "        93,  94,  95,  96,  97,  98,  99, 100])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings = wine_data.points.astype('int32').values \n",
        "np.unique(ratings) #we can see this as an NLP classification problem with 21 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GckK-WM1JlgQ"
      },
      "outputs": [],
      "source": [
        "# here we do our text pre-processing\n",
        "documents = []\n",
        "\n",
        "for i in range(0,len(wine_data)):\n",
        "    #here we discard the punctuation and the special characters\n",
        "    wine_descriptions = re.sub('[^a-zA-Z0-9 ]','',wine_data[\"description\"][i])\n",
        "    # here we change all letter to lower case\n",
        "    wine_descriptions = wine_descriptions.lower()\n",
        "    # here we tokenize the sentences - each sentence is then an array (list) of words\n",
        "    wine_descriptions = wine_descriptions.split()\n",
        "    # here we loop through the different words from the sentences and throw away the \"stopwords\"\n",
        "    wine_descriptions = [word for word in wine_descriptions if not word in set(stopwords.words('english'))]\n",
        "    # here we loop through the different words and we stem them\n",
        "    stemmer = PorterStemmer()\n",
        "    wine_descriptions = [stemmer.stem(word) for word in wine_descriptions]\n",
        "    wine_descriptions = \" \".join(wine_descriptions)\n",
        "    documents.append(wine_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LQp12fDQam6u",
        "outputId": "6d578ff3-1927-49b3-aa35-9b3e20c820c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'onequart wine ferment neutral oak rest stainless steel 125 alcohol light almost airi wine bring immacul fruit flavor appl pear pleas miner mouthfeel offer faintest suggest caramel wind'"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58lsu2HlRrzy",
        "outputId": "ff74d50f-2d06-4d8c-8f3a-703c023abc27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# in the variable documents we should have ALL the different reviews\n",
        "len(set(documents[0].split(' ')).union(set(documents[1].split(' '))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSlRbCJpJ2uO"
      },
      "outputs": [],
      "source": [
        "# Here we make a Bag of Words model so we need the CountVectorizer\n",
        "countVec = CountVectorizer()\n",
        "X = countVec.fit_transform(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5H1D4Kla8Bc",
        "outputId": "40819566-a1eb-4954-ba31-7c906a7b5a8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<40000x20632 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 969159 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc5TRB2MURKa",
        "outputId": "94b69459-d0c2-4d89-9e73-94710dfd0adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 20632)"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape\n",
        "# X so X can be taken as the input features for a machine learning classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI6gDwZyJz9S"
      },
      "outputs": [],
      "source": [
        "# here we designate the output variable and check if we have a class imbalance\n",
        "y = wines_subset[\"points\"]\n",
        "y = y.where(y>=90,other=0).where(y<90,other=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNR13IYOUoR6"
      },
      "outputs": [],
      "source": [
        "# we chose a classfier and we applied it on the whole data (for testing purpuses)\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
        "#model.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1IpqWJTcDm3",
        "outputId": "103f4eb1-ba6d-4970-bbc5-303564e23f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcUFKbO2Vek-",
        "outputId": "6a07a25d-983e-414b-db22-5d26b1e947ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9092"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model.predict(X)\n",
        "AC(y,pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "IvPlQq0yWWlj",
        "outputId": "7c79d194-a5c1-4c20-bdb5-d02c6535a16b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Below 90 points</th>\n",
              "      <th>At least 90 points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Below 90 points</th>\n",
              "      <td>23501</td>\n",
              "      <td>1447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>At least 90 points</th>\n",
              "      <td>2185</td>\n",
              "      <td>12867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Below 90 points  At least 90 points\n",
              "Below 90 points               23501                1447\n",
              "At least 90 points             2185               12867"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(data=CM(y,pred),columns=['Below 90 points','At least 90 points'],index=['Below 90 points','At least 90 points'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6wyDadAV8Gd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=310)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmcSQS54VexD",
        "outputId": "616bc487-f1ec-4d41-bd65-5d2654884806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.83025\n",
            "0.837375\n",
            "0.834875\n",
            "0.841375\n",
            "0.838625\n"
          ]
        }
      ],
      "source": [
        "# the loop for cross-validations\n",
        "accuracies = []\n",
        "i = 0\n",
        "for train,test in skf.split(X,y):\n",
        "  Xtrain = X[train,:]\n",
        "  ytrain = y[train]\n",
        "  Xtest  = X[test,:]\n",
        "  ytest  = y[test]\n",
        "  model.fit(Xtrain,ytrain)\n",
        "  accuracies.append(AC(ytest,model.predict(Xtest)))\n",
        "  print(accuracies[i])\n",
        "  i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezu2iJW4eJYt",
        "outputId": "75eeba9f-8bd6-418f-d79d-08111fbec357"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8365000000000002"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# here the estimation for accuracy is \n",
        "np.mean(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgIOO9ueTVab",
        "outputId": "16e05653-63a4-43f6-cad1-01c2d0977a1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3763"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(y)/len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usp1ylCYKEIF"
      },
      "outputs": [],
      "source": [
        "# here we can make a TF-IDF approach\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tf_idf = vectorizer.fit_transform(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT1HlfiuK5jL"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLX9rYtPepSp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth=20,min_samples_leaf=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUHNXZeWfjZA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=1000,max_depth=1000,min_samples_leaf=100,random_state=310)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnUtvJYtKetX",
        "outputId": "d3b0d75d-0413-4085-fcf3-6e3ef9df9e00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=1000, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=100, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=310,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 93,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_tf_idf,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "cX2VwUTmbRTV",
        "outputId": "d3f4fa17-98cc-4093-ecb4-a07144767455"
      },
      "outputs": [
        {
          "ename": "NotFittedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-2ddc9aa0995d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tf_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \"\"\"\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_ties\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ovo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             raise ValueError(\"break_ties must be False when \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "AC(y,model.predict(X_tf_idf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujudTZ_SkXfl"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "modelsvc = SVC(kernel='poly',degree=3,,C=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5zu595hk0FC",
        "outputId": "e185634b-5089-43f0-ae46-d0311ea26c61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=2.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "execution_count": 97,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelsvc.fit(X_tf_idf,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1kD1BhXrGWe",
        "outputId": "070d056b-3969-4bde-c2f1-eb5ea243be44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.99795"
            ]
          },
          "execution_count": 98,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AC(y,modelsvc.predict(X_tf_idf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacSTLmwbhEO",
        "outputId": "21bc3413-d692-4a47-e0cc-6f71b8585c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.837\n",
            "0.842\n",
            "0.839625\n",
            "0.84675\n",
            "0.839625\n"
          ]
        }
      ],
      "source": [
        "# here we compute the KFold accuracies\n",
        "accuracies = []\n",
        "i = 0\n",
        "for train,test in skf.split(X_tf_idf,y):\n",
        "  Xtrain = X_tf_idf[train,:]\n",
        "  ytrain = y[train]\n",
        "  Xtest  = X_tf_idf[test,:]\n",
        "  ytest  = y[test]\n",
        "  modelsvc.fit(Xtrain,ytrain)\n",
        "  accuracies.append(AC(ytest,modelsvc.predict(Xtest)))\n",
        "  print(accuracies[i])\n",
        "  i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54JuBAYabuU9",
        "outputId": "005bf9dc-6a34-4a1a-ac32-47f9835bd3ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.841"
            ]
          },
          "execution_count": 100,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "P-0xqoC4J_X0",
        "outputId": "10306d1b-3db5-48ab-a3fe-3e07fdf5f29e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 251,
              "width": 378
            },
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#### Visualize the distribution of the wine ratings (points)\n",
        "n, bins, patches = plt.hist(wines_subset[\"points\"].values,10,density=1,facecolor='green',alpha=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ASsfjQKCro"
      },
      "outputs": [],
      "source": [
        "y = wines_subset[\"points\"]\n",
        "y = y.where(y>90,other=0).where(y<=90,other=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlkycIzvKID2"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = tts(X,y,test_size=0.25,random_state=1693)\n",
        "#scale_X = StandardScaler()\n",
        "#X_train = scale_X.fit_transform(X_train)\n",
        "#X_test = scale_X.transform(X_test)\n",
        "classifier = LogisticRegression(random_state=1693,solver='lbfgs')\n",
        "classifier.fit(X_train,Y_train)\n",
        "Y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3FQUwCtKLdV"
      },
      "outputs": [],
      "source": [
        "spc = ['Bad','Good']\n",
        "cm = confusion_matrix(Y_test,Y_pred)\n",
        "pd.DataFrame(cm, columns=spc, index=spc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA8T6AltEMI"
      },
      "source": [
        "###<font color='blue'> Probabilistic Language Modeling \n",
        "\n",
        "**Goal:** Assign the probability that a sequence of words such as $(w_1,w_2,w_3,...w_n)$ occurs:\n",
        "\n",
        "$$\\mathcal{P}(\\text{Sentence})=\\mathcal{P}(w_1,w_2,w_3,...w_n)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2,w_3,w_4...w_n|w_1)=$$\n",
        "\n",
        "Smartphones use this information to predict what the next word you will type will be, for example:\n",
        "\n",
        "$$\\mathcal{P}(w_1,w_2,w_3,w_4)=\\mathcal{P}(w_1)*\\mathcal{P}(w_4,w_3,w_2|w_1)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2|w_1)*\\mathcal{P}(w_4,w_3|w_2,w_1)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2|w_1)*\\mathcal{P}(w_3|w_1,w_2)*\\mathcal{P}(w_4|w_1,w_2,w_3)$$ \n",
        "\n",
        "which mean the probability of word $w_4$ provided the words $w_1, w_2$ and $w_3$ occurred.\n",
        "\n",
        "IMPORTANT: we get a chained application of the Conditional Probability Rule.\n",
        "\n",
        "<font face='Calibri' color='blue' size=4pt>Critical thinking:</span> How do we compute these probability values?</font>\n",
        "\n",
        "<span style=\"font-family:Calibri; color:red; font-size:14pt;\">Reasoning:</span> We compute the frequency of occurrence for different sequences of words.\n",
        "\n",
        "\n",
        "<span style=\"font-family:Calibri; color:darkgreen; font-size:12pt;\"> P(today | It, is, sunny) = 50%\n",
        "The model you use to predict is called the “language model” </span>\n",
        "\n",
        "\n",
        "<span style=\"font-family:Calibri; color:purple; font-size:14pt;\"> Important Concept:</span> The Conditional Probability Rule states that probabilities of an events in the future are defined by the multiplication of all (conditional) probabilities leading to that given event.\n",
        "\n",
        "P(Today, it, was, sunny) = P(Today) * P(it | Today) * P(was | Today, it) * P(sunny | Today, it, was)\n",
        "\n",
        "P(Today, is, the, fiftennth) = P(Today) * P(is | Today) * P(the | Today, is) * P(fifteenth | Today, is, the)\n",
        "\n",
        "1. Unigram Models:\n",
        "        a. P(rainy | Today, it, was) ~ P(Today) * P(it) * P(was)\n",
        "2. Bigram Models:\n",
        "        a. P(rainy| Today, it, was) ~ P(rainy | was)\n",
        "3. N-gram models:\n",
        "        a. Same as the above, but for arbitrary distances.\n",
        "        b. For example a tri-gram: P(rainy | Today, it, was)\n",
        "            \n",
        "Often used in nested ways (i.e., a 3-gram model + unigram).\n",
        "\n",
        "\n",
        "### Evaluating NLP\n",
        "\n",
        "• The goal of any NLP activity is important in deciding how to evaluate it.\n",
        "\n",
        "• In a Bag of Words model, evaluation can come from classification accuracy (i.e., you have a training and test dataset).\n",
        "\n",
        "• But what if you’re writing an algorithm that predicts the next word for a texting app?\n",
        "\n",
        "### Perplexity an evaluative measure for NLP\n",
        "\n",
        "One might expect a model to be good at predicting cold in this sentence:\n",
        "\n",
        "“It is cold.”\n",
        "\n",
        "And not as good at predicting:\n",
        "\n",
        "“It is very cool outside when the winter is cold”\n",
        "\n",
        "For a variety of reasons; the biggest is the complexity/length of the sentence.\n",
        "\n",
        "• Perplexity is a measurement of how well a probability model predicts a test data. In the context of Natural Language Processing, perplexity is one way to evaluate language models.\n",
        "\n",
        "• Perplexity is an exponentiation of the entropy.\n",
        "\n",
        "• Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of an *entropy*.\n",
        "\n",
        "• The goal is to minimize Perplexity(W).\n",
        "\n",
        "Calculation of perplexity for a full a sequence of words: \n",
        "\n",
        "$$\\sqrt{\\prod_{i=1}^{n}\\frac{1}{P(w_i|w_{1}w_{2}...w_{i-1})}}$$\n",
        "\n",
        "Important applciations for Natural Language Processing:\n",
        "\t\n",
        "    • Sentiment Analysis\n",
        "\t\n",
        "    • Speech Recognition\n",
        "\t\n",
        "    • Information Retrieval\n",
        "\n",
        "    • Question Answering\n",
        "\n",
        "<span style=\"font-family:Calibri; color:blue; font-size:14pt;\">Big Idea:</span> Represent words as vectors: GloVe, Word2Vec algorithms (both are based on neural networks). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvNZkDf-3re"
      },
      "source": [
        "## Text Pre-Processing\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=18NPGiY9qskAusVD-hzQQ0Lz2uZ8nRyiX' width='500px' />\n",
        "\n",
        "<figcaption>Image Caption</figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmQv06jbAbF"
      },
      "source": [
        "## CBOW (continuous Bag of Words)\n",
        "\n",
        "**CBOW** predicts words from the surrounding context words; it treats one context as one independent observation.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1L7Ol7refO3mMo92dTytS4CShUfPnsmCB' width='250px' />\n",
        "\n",
        "\n",
        "\n",
        "The CBOW model architecture (Source: https://arxiv.org/pdf/1301.3781.pdf Mikolov el al.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xziwtKthToWe"
      },
      "source": [
        "## Global Vectors for Word Representations (GloVe)\n",
        "\n",
        "Example for using the vector words:  <font color='red'>monarch - man = queen.</font>\n",
        "\n",
        "The main idea is that we can do more than just counting occurences but rather represent the words from the vocabulary of a language as vectors whose entries are real numbers. As such, the GloVe algorithm is analysing word *co-occurrencies* within a text corpus; the steps are as follows:\n",
        "\n",
        "1.   A *co-occurence* matrix $X$ is created where its entries $X_{ij}$ represent how often word $i$ is present in the context of the word $j$. Thus there is a parsing of the corpus for building the matrix $X$ and then the model is constructed based on this matrix.\n",
        "2.   For the words $i$ and $j$ we create vectors $\\vec{w}_i$ and $\\vec{w}_j$ such that $$\\vec{w}_i^T\\cdot\\vec{w}_j+b_i+b_j=\\log (X_{ij})$$ where $b_i$ and $b_j$ are scalar *bias* terms (such as the *y-intercepts* for a linear regression model). We want to build word vectors that retain useful information of how words $i$ and $j$ co-occur.\n",
        "3.   In order to determine the entries for the *word vectors* $\\vec{w}_i$, we minimize the following objective function $$J:=\\sum_{i=1}^{V}\\sum_{j=1}^{V}f(X_{ij}) \\left(\\vec{w}_i^T\\cdot\\vec{w}_j+b_i+b_j-\\log (X_{ij})\\right)^2$$\n",
        "4.   The function $f$ is chosen in order to prevent the skewing of the objective function by the words that co-occur too often. In this sense a choice for the function $f$ could be $$f(X_{ij}):=\\begin{cases}\n",
        "\\left(\\frac{X_{ij}}{x_{max}}\\right)^{\\alpha} \\text{if} \\;\\; X_{ij}<x_{max} \\\\\n",
        "1 \\;\\;\\; \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$ where $\\alpha$ and $x_{max}$ can be adjusted by the user. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbcPwVKYdCP",
        "outputId": "e81be1d9-6972-43a0-a65c-3aca3ce0e903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting glove-python-binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 38.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 194 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 204 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 215 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 235 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 256 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 286 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 307 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 317 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 337 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 348 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 368 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 378 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 389 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 399 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 409 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 419 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 430 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 440 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 450 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 460 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 471 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 481 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 491 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 501 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 512 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 522 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 532 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 542 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 552 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 573 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 583 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 593 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 604 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 614 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 624 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 634 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 645 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 655 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 665 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 675 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 686 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 696 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 706 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 716 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 727 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 737 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 747 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 757 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 768 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 778 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 788 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 798 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 808 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 819 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 829 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 839 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 849 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 860 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 870 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 880 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 890 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 901 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 911 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 921 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 931 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 942 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 948 kB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install glove-python-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjH7krEaYeTs"
      },
      "outputs": [],
      "source": [
        "from glove import Corpus, Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH0wjTZ8Yhah"
      },
      "outputs": [],
      "source": [
        "text = [['Hello', 'this','presentation', 'on', 'how','convert' ,'word','number','format'],\n",
        "        ['this' ,'beautiful', 'day'],['Daniel','will','going' , 'office','today'],\n",
        "        ['Want', 'also','introduce','Colab','good','tool','convert','word','number']]\n",
        "# text = \"The chocolate is delicious but it may not be always good for you. Homemade chocolate is fun to make. There are many recipes online.\"\n",
        "# creating a corpus object\n",
        "corpus = Corpus() \n",
        "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(text, window=10)\n",
        "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "#We can set the learning rate as it uses Gradient Descent and number of components\n",
        "glove = Glove(no_components=5, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=50, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGUr23D3Yql0",
        "outputId": "1acb3658-f07a-4608-a79c-3f9d72966aac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('format', 0.9377103562998411),\n",
              " ('number', 0.794133910513137),\n",
              " ('Daniel', 0.6019566689918101),\n",
              " ('convert', 0.4698554931090687)]"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glove.most_similar('Hello')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4Oqt4v-Ytz2"
      },
      "outputs": [],
      "source": [
        "print(corpus.matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYin__qSZK0G"
      },
      "source": [
        "## GloVe Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1fK_16oZMEL",
        "outputId": "b2c82c74-fa72-4c97-d49b-7634446b3517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pprint\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAxpLzlGZSLr"
      },
      "outputs": [],
      "source": [
        "text = open(\"drive/My Drive/Colab Notebooks/Christmas_Carol.txt\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuzQcGtxZYGk"
      },
      "outputs": [],
      "source": [
        "dataset = nltk.sent_tokenize(text) \n",
        "for i in range(len(dataset)): \n",
        "    dataset[i] = dataset[i].lower() \n",
        "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
        "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "68TcQiv2ZbC4",
        "outputId": "7c59979e-4a18-4577-d1b5-4eff37ea303a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' you ll want all day to morrow i suppose '"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjjakfYQZgbW"
      },
      "outputs": [],
      "source": [
        "def InfoExtract(document):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "    sentences = [nltk.pos_tag(sent) for sent in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRoXD9MEZlGf"
      },
      "outputs": [],
      "source": [
        "InfoExtract(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKT81feLZnyT"
      },
      "outputs": [],
      "source": [
        "sentences = [nltk.word_tokenize(sent) for sent in dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFJNNSz-toTA",
        "outputId": "37daf1fd-b3ca-49c2-debb-11152e233aee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scrooge',\n",
              " 'fell',\n",
              " 'upon',\n",
              " 'his',\n",
              " 'knees',\n",
              " 'and',\n",
              " 'clasped',\n",
              " 'his',\n",
              " 'hands',\n",
              " 'before',\n",
              " 'his',\n",
              " 'face']"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences[327]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMtjt4MFZvPo"
      },
      "source": [
        "### Here we apply the GloVe algorithm to create word vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5kwHOjOZwlH"
      },
      "outputs": [],
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(sentences, window=12)\n",
        "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "#We can set the learning rate as it uses Gradient Descent and number of components\n",
        "glove = Glove(no_components=10, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=1000, no_threads=20, verbose=False)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwNjQfBuZ6mX",
        "outputId": "98ae2ff3-0cf6-4efe-bc3b-1fc00d41732b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4262x4262 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 122623 stored elements in COOrdinate format>"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus.matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzRkzXmuZ9c8",
        "outputId": "fc657da8-d646-4e14-caf9-25c695332208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('day', 0.9185604412013397),\n",
              " ('merry', 0.9156450891535083),\n",
              " ('business', 0.90382657617194),\n",
              " ('sends', 0.861967957395055)]"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glove.most_similar('christmas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfGwxhjpSyr1"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "It is a combination of models for representing the contextual distribution of words in a corpus.\n",
        "\n",
        "Playground: http://projector.tensorflow.org/\n",
        "\n",
        "There are two main algorithms: **CBOW** (Continuous Bag of Words) and **Skip-Gram**.\n",
        "\n",
        "**CBOW** predicts words from the surrounding context words; it treats one context as one independent observation.\n",
        "\n",
        "**Skip-Gram** predicts the surrounding context words from the target words (in a sense it is the \"inverse\" of CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knn7tRDWN6Y_",
        "outputId": "9eccd583-49a2-4a1a-e441-0ea0367e7add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing all necessary modules \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import warnings \n",
        "  \n",
        "warnings.filterwarnings(action = 'ignore') \n",
        "  \n",
        "import gensim \n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAPDUr83RT4d"
      },
      "source": [
        "### Test Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZFZLWdsRQ85"
      },
      "outputs": [],
      "source": [
        "#  Reads text file \n",
        "sample = text\n",
        "  \n",
        "# Replaces escape character with space \n",
        "#f = s.replace(\"\\n\", \" \") \n",
        "\n",
        "f = text\n",
        "  \n",
        "data = [] \n",
        "  \n",
        "# iterate through each sentence in the file \n",
        "for i in sent_tokenize(f): \n",
        "    temp = [] \n",
        "      \n",
        "    # tokenize the sentence into words \n",
        "    for j in word_tokenize(i): \n",
        "        temp.append(j.lower()) \n",
        "  \n",
        "    data.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ImJQxywaVk",
        "outputId": "73ec43f5-55b0-4f8e-f00d-859356cf5449"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['and', 'closed', 'it', 'with', 'a', 'bang', '.']"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[234]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxLhQMZ5Rlor"
      },
      "source": [
        "### CBOW Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DupccuG9Rl56",
        "outputId": "6bbc7b97-fba3-4a50-f7f4-1e9552328b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'candle' and 'christmas' - CBOW :  0.98483485\n",
            "Cosine similarity between 'scrooge' and 'christmas' - CBOW :  0.99985504\n"
          ]
        }
      ],
      "source": [
        "# Create CBOW model \n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
        "                              size = 50, window = 9,sg=0) \n",
        "# Print results \n",
        "print(\"Cosine similarity between 'candle' \" + \n",
        "               \"and 'christmas' - CBOW : \", \n",
        "    model1.similarity('candle', 'christmas')) \n",
        "      \n",
        "print(\"Cosine similarity between 'scrooge' \" +\n",
        "                 \"and 'christmas' - CBOW : \", \n",
        "      model1.similarity('scrooge', 'christmas')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a6MmGBPR4N4"
      },
      "source": [
        "### Skip-Gram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXuf8lYER4la",
        "outputId": "c78c77cb-abcf-4d08-a68c-11a52c07fd2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'ghost' and 'christmas' - Skip-Gram :  0.99325514\n",
            "Cosine similarity between 'scrooge' and 'christmas' - Skip-Gram :  0.9892585\n"
          ]
        }
      ],
      "source": [
        "# Create Skip Gram model \n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 50, \n",
        "                                             window = 9, sg = 1) \n",
        "  \n",
        "# Print results \n",
        "print(\"Cosine similarity between 'ghost' \" + \n",
        "               \"and 'christmas' - Skip-Gram : \", \n",
        "    model2.similarity('ghost', 'christmas')) \n",
        "      \n",
        "print(\"Cosine similarity between 'scrooge' \" +\n",
        "                 \"and 'christmas' - Skip-Gram : \", \n",
        "      model2.similarity('scrooge', 'christmas')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WqlfOlVSK_t",
        "outputId": "10547908-2a94-47f1-d159-113dd1bd83d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('with', 0.9999064803123474),\n",
              " ('on', 0.9999052286148071),\n",
              " ('an', 0.9999028444290161),\n",
              " ('in', 0.9999011158943176),\n",
              " ('there', 0.9998980760574341),\n",
              " (',', 0.9998955726623535),\n",
              " (\"'s\", 0.9998926520347595),\n",
              " ('we', 0.9998918771743774),\n",
              " ('and', 0.9998918771743774),\n",
              " ('by', 0.9998900890350342)]"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.wv.most_similar(positive='ghost')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "More Applications with NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
