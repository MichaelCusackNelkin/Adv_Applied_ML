{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA 410 Repeated Boosting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jry4UFwXSU_q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.linalg import lstsq\n",
        "from scipy.sparse.linalg import lsmr\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split as tts\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "\n",
        "Update the algorithms we have for repeated boosting.\n",
        "Compare with more boosting algorithms such as LightGBM (and, time allows, Catboost)"
      ],
      "metadata": {
        "id": "Z8TVD2OqSdte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tricubic Kernel\n",
        "def Tricubic(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,70/81*(1-d**3)**3)\n",
        "\n",
        "# Quartic Kernel\n",
        "def Quartic(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,15/16*(1-d**2)**2)\n",
        "\n",
        "# Epanechnikov Kernel\n",
        "def Epanechnikov(x):\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape(-1,1)\n",
        "  d = np.sqrt(np.sum(x**2,axis=1))\n",
        "  return np.where(d>1,0,3/4*(1-d**2)) "
      ],
      "metadata": {
        "id": "nxxOFqG0Sv-Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the kernel local regression model\n",
        "\n",
        "def lw_reg(X, y, xnew, kern, tau, intercept):\n",
        "    # tau is called bandwidth K((x-x[i])/(2*tau))\n",
        "    n = len(X) # the number of observations\n",
        "    yest = np.zeros(n)\n",
        "\n",
        "    if len(y.shape)==1: # here we make column vectors\n",
        "      y = y.reshape(-1,1)\n",
        "\n",
        "    if len(X.shape)==1:\n",
        "      X = X.reshape(-1,1)\n",
        "    \n",
        "    if intercept:\n",
        "      X1 = np.column_stack([np.ones((len(X),1)),X])\n",
        "    else:\n",
        "      X1 = X\n",
        "\n",
        "    w = np.array([kern((X - X[i])/(2*tau)) for i in range(n)]) # here we compute n vectors of weights\n",
        "\n",
        "    #Looping through all X-points\n",
        "    for i in range(n):          \n",
        "        W = np.diag(w[:,i])\n",
        "        b = np.transpose(X1).dot(W).dot(y)\n",
        "        A = np.transpose(X1).dot(W).dot(X1)\n",
        "        #A = A + 0.001*np.eye(X1.shape[1]) # if we want L2 regularization\n",
        "        #theta = linalg.solve(A, b) # A*theta = b\n",
        "        beta, res, rnk, s = lstsq(A, b)\n",
        "        yest[i] = np.dot(X1[i],beta)\n",
        "    if X.shape[1]==1:\n",
        "      f = interp1d(X.flatten(),yest,fill_value='extrapolate')\n",
        "    else:\n",
        "      f = LinearNDInterpolator(X, yest)\n",
        "    output = f(xnew) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "    if sum(np.isnan(output))>0:\n",
        "      g = NearestNDInterpolator(X,y.ravel()) \n",
        "      # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
        "      output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
        "    return output"
      ],
      "metadata": {
        "id": "XBO1QXA8TEXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boosted_lwr(X, y, xnew, kern, tau, intercept, model_boosting, nboost):\n",
        "  # we need decision trees\n",
        "  # for training the boosted method we use X and y\n",
        "  Fx = lw_reg(X,y,X,kern,tau,intercept) # we need this for training the Decision Tree\n",
        "  # Now train the Decision Tree on y_i - F(x_i)\n",
        "  #new_y = y - Fx\n",
        "  #model = DecisionTreeRegressor(max_depth=2, random_state=123)\n",
        "  #model = RandomForestRegressor(n_estimators=100,max_depth=2)\n",
        "  #model = model_xgb\n",
        "  #model_boosting.fit(X,new_y)\n",
        "  output = booster(X,y,xnew,kern,tau,model_boosting,nboost)\n",
        "  return output "
      ],
      "metadata": {
        "id": "FkZ6_pXPTIvF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def booster(X,y,xnew,kern,tau,model_boosting,nboost):\n",
        "  Fx = lw_reg(X,y,X,kern,tau,True)\n",
        "  Fx_new = lw_reg(X,y,xnew,kern,tau,True)\n",
        "  new_y = y - Fx\n",
        "  output = Fx\n",
        "  output_new = Fx_new\n",
        "  for i in range(nboost):\n",
        "    model_boosting.fit(X,new_y)\n",
        "    output += model_boosting.predict(X)\n",
        "    output_new += model_boosting.predict(xnew)\n",
        "    new_y = y - output\n",
        "  return output_new"
      ],
      "metadata": {
        "id": "bBAaBCINTMGe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars = pd.read_csv('drive/MyDrive/Data Sets/cars.csv')"
      ],
      "metadata": {
        "id": "BUXTUxdaWLEF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = cars[['ENG','CYL','WGT']].values\n",
        "y = cars['MPG'].values"
      ],
      "metadata": {
        "id": "rOQlhzeKWwf3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_boosting = RandomForestRegressor(n_estimators=100,max_depth=3)"
      ],
      "metadata": {
        "id": "Lzl0G05MWy4q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale = StandardScaler()"
      ],
      "metadata": {
        "id": "rnmt3eIeXD95"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xscaled = scale.fit_transform(X)"
      ],
      "metadata": {
        "id": "fgrX5VKKXLYF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = boosted_lwr(xtrain,ytrain,xtest,Tricubic,1,True,model_boosting,1)"
      ],
      "metadata": {
        "id": "RW7ob-f2XPPL"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(ytest,yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gHZXlRnXcfA",
        "outputId": "d9777b61-25d6-4918-d475-cb82a9c55fec"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.963291623297664"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "Ffa6LfGpYKH4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we want more nested cross-validations\n",
        "\n",
        "\n",
        "mse_blwr = []\n",
        "\n",
        "mse_xgb = []\n",
        "\n",
        "for i in range(5):\n",
        "  kf = KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "  # this is the Cross-Validation Loop\n",
        "  for idxtrain, idxtest in kf.split(X):\n",
        "    xtrain = X[idxtrain]\n",
        "    ytrain = y[idxtrain]\n",
        "    ytest = y[idxtest]\n",
        "    xtest = X[idxtest]\n",
        "    xtrain = scale.fit_transform(xtrain)\n",
        "    xtest = scale.transform(xtest)\n",
        "    dat_train = np.concatenate([xtrain,ytrain.reshape(-1,1)],axis=1)\n",
        "    dat_test = np.concatenate([xtest,ytest.reshape(-1,1)],axis=1)\n",
        "    #yhat_lwr = lw_reg(xtrain,ytrain, xtest,Epanechnikov,tau=0.9,intercept=True)\n",
        "    #yhat_blwr = boosted_lwr(xtrain,ytrain, xtest,Epanechnikov,tau=0.9,intercept=True)\n",
        "    yhat_blwr = boosted_lwr(xtrain,ytrain,xtest,Tricubic,1,True,model_boosting,2)\n",
        "    #model_rf = RandomForestRegressor(n_estimators=100,max_depth=3)\n",
        "    #model_rf.fit(xtrain,ytrain)\n",
        "    #yhat_rf = model_rf.predict(xtest)\n",
        "    model_xgb = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=1)\n",
        "    model_xgb.fit(xtrain,ytrain)\n",
        "    yhat_xgb = model_xgb.predict(xtest)\n",
        "    #model_nn.fit(xtrain,ytrain,validation_split=0.2, epochs=500, batch_size=10, verbose=0, callbacks=[es])\n",
        "    #yhat_nn = model_nn.predict(xtest)\n",
        "    # here is the application of the N-W regressor\n",
        "    #model_KernReg = KernelReg(endog=dat_train[:,-1],exog=dat_train[:,:-1],var_type='ccc',ckertype='gaussian')\n",
        "    #yhat_sm, yhat_std = model_KernReg.fit(dat_test[:,:-1])\n",
        "    #mse_lwr.append(mse(ytest,yhat_lwr))\n",
        "    mse_blwr.append(mse(ytest,yhat_blwr))\n",
        "    #mse_rf.append(mse(ytest,yhat_rf))\n",
        "    mse_xgb.append(mse(ytest,yhat_xgb))\n",
        "    ##mse_nn.append(mse(ytest,yhat_nn))\n",
        "    #mse_NW.append(mse(ytest,yhat_sm))\n",
        "#print('The Cross-validated Mean Squared Error for LWR is : '+str(np.mean(mse_lwr)))\n",
        "print('The Cross-validated Mean Squared Error for Boosted LWR is : '+str(np.mean(mse_blwr)))\n",
        "#print('The Cross-validated Mean Squared Error for RF is : '+str(np.mean(mse_rf)))\n",
        "print('The Cross-validated Mean Squared Error for XGB is : '+str(np.mean(mse_xgb)))\n",
        "#print('The Cross-validated Mean Squared Error for NN is : '+str(np.mean(mse_nn)))\n",
        "#print('The Cross-validated Mean Squared Error for Nadarya-Watson Regressor is : '+str(np.mean(mse_NW)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK7lTpsVYWDk",
        "outputId": "afcd069b-96ce-4a49-ed15-8c1b3d3de6b3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for Boosted LWR is : 16.702174726913885\n",
            "The Cross-validated Mean Squared Error for XGB is : 16.559417572167884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge09lHymZoz4",
        "outputId": "e99a85b8-ab35-4ef9-882b-f370c0d89552"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_a0lx4hbZqT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}